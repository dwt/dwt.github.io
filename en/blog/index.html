
<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="../../static/bootstrap-4.1.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="../../static/style.css">
    <link rel="stylesheet" href="../../static/pygments.css">
    <title>Blog</title>
    <link rel="alternate" type="application/atom+xml" title="RSS: Martin HÃ¤ckers Blog Artikel" href="../../blog/feed.xml" />
  </head>
  <body>
    <header>
      <nav class="navbar navbar-expand-sm">
  <a href="../" class="navbar-brand ">ğŸ </a>
  <input type="checkbox" id="navbar-toggle-checkbox">
  <label for="navbar-toggle-checkbox" class="navbar-brand navbar-toggle d-sm-none float-right" aria-label="Navigation Umschalten">
    <span></span>
  </label>
  <ul class="navbar-nav collapse navbar-collapse">
    
      <li class="nav-item "><a href="../work/" class="nav-link">Professional software development</a></li>
    
      <li class="nav-item "><a href="../projects/" class="nav-link">Projects</a></li>
    
      <li class="nav-item "><a href="../publications/" class="nav-link">Publications and talks</a></li>
    
      <li class="nav-item active"><a href="./" class="nav-link">Blog<span class="sr-only">(ausgewÃ¤hlt)</span></a></li>
    
      <li class="nav-item "><a href="../categories/" class="nav-link">Categories</a></li>
    
    <li class="nav-item ml-auto">
      <a class=nav-link href="../../blog/">ğŸ‡©ğŸ‡ª</a>
    </li>
    <li class="nav-item pull-right">
      <a class=nav-link href="./">ğŸ‡¬ğŸ‡§</a>
    </li>
  </ul>
</nav>
<nav class="breadcrumb">
  

  

<a class="breadcrumb-item " href="../">ğŸ </a>


<a class="breadcrumb-item active" href="./">Blog</a>

</nav>
    </header>
    <article class="page blog  container-fluid">
      
  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/9/warum-man-backups-und-disaster-recovery-zusammen-denken-sollte/">
        Backup ohne verprobte Recovery ist wertlos â€“ 5 GrÃ¼nde
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-09-29">Monday, September 29, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/9/warum-man-backups-und-disaster-recovery-zusammen-denken-sollte/backup-ohne-recovery.png" alt="Backup und Recovery"></p>
<p>Auf der DevOpsCon 25 in Berlin habe ich viel aus dem Vortrag <a href="https://devopscon.io/devsecops/backup-disaster-recovery/">Backup and Disaster Recovery: Business as Usual or What Needs to Change Now? - DevOps Conference &amp; Camps</a> gezogen. Zum technischen Inhalt gehe ich noch mal Separat ein, aber zuerst wollte ich meine SchlÃ¼ssel-Lernergebnisse auf einer sehr hohen FlughÃ¶he mitbringen.</p>
<h2>1. Backups ohne Restore sind nur DatenfriedhÃ¶fe</h2>
<p>Ein Backup ist kein Wert an sich. Es ist nur die Basis fÃ¼r GeschÃ¤ftskontinuitÃ¤t â€“ erst der funktionierende Restore bringt das Unternehmen zurÃ¼ck ins GeschÃ¤ft.</p>
<h2>2. Zeit entscheidet Ã¼ber Resilienz</h2>
<p>Recovery Time Objective (RTO) ist der kritische Faktor â€“ nicht die schiere Menge oder Existenz von Kopien. Entscheidend ist: Wie lange darf welcher Teil des GeschÃ¤fts ausfallen, bis es ernsthafte SchÃ¤den nimmt?</p>
<h2>3. Kontinuierlicher Minimal-Restore trennt Dauer von Ausfallzeit</h2>
<p>Ein innovativer Ansatz ist, kontinuierlich eine schlanke, nicht skalierte Version der Systeme aus den Backups hochzufahren. Damit lÃ¤sst sich jederzeit beweisen: Restore funktioniert. Und: Die Dauer des eigentlichen Restore-Vorgangs aus den Backups kann nahezu beliebig sein, ohne wesentlich das RTO zu gefÃ¤hrden.</p>
<h2>4. Vorhersagbare Skalierung statt unberechenbarer Wiederanlauf</h2>
<p>Im Notfall geht es nicht darum, <em>ob</em> das Backup lÃ¤uft, sondern <em>wie schnell</em> man wieder auf ausreichende KapazitÃ¤t kommt. Wer Skalierung auf Abruf plant, kennt die Antwort: â€In X Minuten / Stunden ist die  Leistung verfÃ¼gbar.â€œ Das macht den Unterschied zwischen Chaos und geplanter Resilienz.</p>
<h2>5. Kosteneffizienz und Compliance in einem</h2>
<p>Statt teurer Standby-Infrastruktur entsteht ein Modell, das laufend minimale Kosten verursacht, aber im Ernstfall sofort hochskaliert. Dazu kommt: Unternehmen erfÃ¼llen so auch regulatorische Anforderungen nach nachweisbarer WiederanlauffÃ¤higkeit.</p>
<p><strong>Fazit:</strong>
Backups sind nur der Anfang. Erst wenn Restore und Disaster Recovery gemeinsam gedacht werden â€“ mit kontinuierlichem Minimal-Restore und skalierbarer Infrastruktur â€“ entsteht echte Business-KontinuitÃ¤t.</p>

    </section>
    
      <footer>
        <a href="2025/9/warum-man-backups-und-disaster-recovery-zusammen-denken-sollte/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/9/textbearbeitung-mit-grep-tr-cut-awk-und-sed/">
        Textbearbeitung auf der Shell: grep, cut, awk, sed und tr
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-09-25">Thursday, September 25, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/9/textbearbeitung-mit-grep-tr-cut-awk-und-sed/tr-in-action.png" alt="`tr` in aktion"></p>
<p>Diese fÃ¼nf kleinen Tools sind echte Arbeitspferde fÃ¼r jeden, der mit Text auf der Kommandozeile arbeitet. Sie haben viele Optionen â€“ aber man braucht nicht alles zu kennen. Schon mit ein paar Grundbefehlen kann man 80â€¯% der typischen Aufgaben lÃ¶sen.</p>
<h3>1. <code>grep</code> â€“ Zeilen finden</h3>
<p>grep filtert Textzeilen anhand von Mustern. Praktisch, wenn man in langen Outputs schnell das Relevante sehen will.</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Textzeilen ausgeben, die ein Wort enthalten</td>
<td><code>grep PATTERN</code></td>
<td>`cat protokoll.txt</td>
<td>grep "Fehler"`</td>
</tr>
<tr>
<td>Zeilen ausschlieÃŸen</td>
<td><code>grep -v PATTERN</code></td>
<td><code>grep -v "^#" protokoll.txt</code></td>
</tr>
<tr>
<td>In einem ganzen Projektbaum nach</td>
<td><code>grep -r PATTERN DIR</code></td>
<td><code>grep -r "TODO" src/</code></td>
</tr>
</tbody>
</table>
<p><strong>Tipps</strong></p>
<ul>
<li><code>-i</code> ignoriert GroÃŸ/Kleinschreibung</li>
<li><code>-e</code> aktiviert RegulÃ¤re AusdrÃ¼cke (unter linux gibt es noch <code>-P</code> fÃ¼r Perl-kompatible Regex)</li>
</ul>
<p>Kombinationen Ã¼ber Pipes machen grep besonders stark:</p>
<div class="hll"><pre><span></span>grep<span class="w"> </span>-r<span class="w"> </span>-P<span class="w"> </span><span class="s2">&quot;def \w*\(&quot;</span><span class="w"> </span>.<span class="w"> </span>--after-context<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span><span class="s2">&quot;foo&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span><span class="s2">&quot;bar&quot;</span>
</pre></div>
<p>FÃ¼r groÃŸe Projekte lohnt sich ripgrep (rg), weil es schneller ist, <code>.gitignore</code> respektiert und regulÃ¤re AusdrÃ¼cke standardmÃ¤ÃŸig aktiviert.</p>
<h3>2. <code>cut</code> â€“ Spalten und Zeichen</h3>
<p><code>cut</code> schneidet Spalten oder Zeichen aus Textzeilen heraus. Funktioniert am besten, wenn der Trenner ein einzelnes Zeichen ist.</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spalte 2 eine CSV <sup class="footnote-ref" id="fnref-csv"><a href="#fn-csv">1</a></sup></td>
<td><code>-d ',' -f 2</code></td>
<td><code>cut -d ',' -f 2 daten.csv</code></td>
</tr>
<tr>
<td>Zeichen 5â€‘10 einer Zeile</td>
<td><code>-c 5-10</code></td>
<td><code>cut -c 5-10 string.txt</code></td>
</tr>
<tr>
<td>Mehrere Felder</td>
<td><code>-f 1,3,5</code></td>
<td><code>cut -d ';' -f 1,3,5 daten.txt</code></td>
</tr>
</tbody>
</table>
<p>Bei Whitespace-getrennten Daten stÃ¶ÃŸt cut an Grenzen â€“ da ist <code>awk</code> besser.</p>
<h3>3. <code>awk</code> â€“ Felder und Muster</h3>
<p><code>awk</code> versteht Texte als Felder, getrennt durch Whitespace oder ein angegebenes Zeichen. Wenn man mÃ¶chte, kann man mit <code>awk</code> Text-Dateien fast wie Datenbanken abfragen, aber fÃ¼r den Anfang:</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spalten ausgeben</td>
<td><code>{print $1, $3}</code></td>
<td><code>awk '{print $1, $3}' daten.txt</code></td>
</tr>
<tr>
<td>Letzte Spalte ausgeben</td>
<td><code>{print $NF}</code></td>
<td><code>awk '{print $NF}' daten.txt</code></td>
</tr>
<tr>
<td>Summe einer Spalte</td>
<td><code>{s+=$2} END {print s}</code></td>
<td><code>awk '{s+=$2} END {print s}' zahlen.txt</code></td>
</tr>
</tbody>
</table>
<p><strong>NÃ¼tzliche Variablen</strong></p>
<ul>
<li><code>NF</code> = Anzahl Felder in der Zeile</li>
<li><code>NR</code> = aktuelle Zeilennummer</li>
</ul>
<h3>4. <code>sed</code> â€“ Suchen und Ersetzen</h3>
<p><code>sed</code> ist ein Stream-Editor: ideal fÃ¼r Ersetzungen und einfache Transformationen.</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ersetzen</td>
<td><code>s/alt/neu/g</code></td>
<td><code>sed 's/Fehler/Warning/g' log.txt</code></td>
</tr>
</tbody>
</table>
<p>Vorsicht: Nie direkt in die gleiche Datei schreiben mit &gt; â€“ sonst Ã¼berschreibst du sie, bevor sie gelesen wurde. <strong>DAMIT HABE ICH SCHON DATEN VERLOREN</strong> Stattdessen:</p>
<div class="hll"><pre><span></span>sed<span class="w"> </span>-i<span class="w"> </span><span class="s1">&#39;s/alt/neu/g&#39;</span><span class="w"> </span>datei.txt<span class="w">   </span><span class="c1"># Direkt in der Datei Ã¤ndern</span>
</pre></div>
<h3>5. <code>tr</code> â€“ Zeichen Ã¼bersetzen</h3>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>GroÃŸâ†’Klein</td>
<td><code>tr [:upper:][:lower:]</code></td>
<td><code>tr '[:upper:]' '[:lower:]' &lt; input.txt</code></td>
</tr>
<tr>
<td>Leerzeichen lÃ¶schen</td>
<td><code>tr -d ' '</code></td>
<td><code>tr -d ' ' &lt; file</code></td>
</tr>
<tr>
<td>ROT13 (Caesarâ€‘Shift)</td>
<td><code>tr 'a-z' 'n-za-m'</code></td>
<td><code>tr 'a-z' 'n-za-m' &lt; text.txt</code></td>
</tr>
<tr>
<td>Mehrere Zeichen gleichzeitig</td>
<td><code>tr 'abc' 'ABC'</code></td>
<td><code>tr 'abc' 'ABC' &lt; input.txt</code></td>
</tr>
</tbody>
</table>
<p>Beispiel: <code>$PATH</code> lesbarer machen:</p>
<div class="hll"><pre><span></span>â¯<span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="nv">$PATH</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>tr<span class="w"> </span><span class="s1">&#39;:&#39;</span><span class="w"> </span><span class="s1">&#39;\n&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>nl
</pre></div>
<h2>Fazit</h2>
<ul>
<li><strong><code>grep</code></strong>: Zeilen nach Mustern filtern</li>
<li><strong><code>cut</code></strong>: Spalten oder Zeichen ausschneiden.</li>
<li><strong><code>awk</code></strong>: Felder flexibel verarbeiten und berechnen.</li>
<li><strong><code>sed</code></strong>: Ersetzen und transformieren</li>
<li><strong><code>tr</code></strong>: Zeichen umwandeln oder lÃ¶schen</li>
</ul>
<p>ğŸ‘‰ Zusammengeschaltet mit Pipes (<code>|</code>) werden diese Tools zu einem Schweizer Taschenmesser fÃ¼r Textbearbeitung â€“ schnell, skriptbar und Ã¼berall verfÃ¼gbar.</p>
<div class="footnotes">
<hr>
<ol><li id="fn-csv"><p>CSV = Comma-Separated Values, kann natÃ¼rlich auch maskierte Kommas in dem Wert enthalten, was dieser Befehl geflissentlich ignoriert oder falsch macht. Verwendet zum CSV-Parsen also bitte nicht diesen Shell-Befehl. Dieser Befehle sind dafÃ¼r da, auf der Shell schnell mal in eine Datei hineinzuschauen. Wenn das Ergebnis gut genug ist, kann man es auch weiter verarbeiten.<a href="#fnref-csv" class="footnote">&#8617;</a></p></li>
</ol>
</div>

    </section>
    
      <footer>
        <a href="2025/9/textbearbeitung-mit-grep-tr-cut-awk-und-sed/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/8/arbeiten-mit-json-and-yaml-auf-der-shell/">
        Arbeiten mit JSON &amp; YAML auf der Shell
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-08-25">Monday, August 25, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/8/arbeiten-mit-json-and-yaml-auf-der-shell/yless.png" alt="yaml ganz angenem auf der Shell"></p>
<p>Arbeiten mit strukturierten Datenformaten auf der Shell kann anstrengend sein â€“ <strong>wenn man noch nicht die richtigen Tools dafÃ¼r hat</strong>.
Ob JSON aus einer API, YAML aus Kubernetes-Manifests oder riesige Logfiles â€“ ohne passende Helferlein endet man schnell bei unÃ¼bersichtlichem <code>grep</code>, <code>less</code> und Copy&amp;Paste.</p>
<p>Zum GlÃ¼ck gibt es eine Reihe von Werkzeugen, die genau dafÃ¼r gemacht sind:</p>
<ul>
<li><strong>jq</strong> â€“ JSON lesen, filtern und transformieren â€“ <a href="https://jqlang.org">https://jqlang.org</a></li>
<li><strong>jo</strong> â€“ JSON in der Shell erzeugen â€“ <a href="https://github.com/jpmens/jo">https://github.com/jpmens/jo</a></li>
<li><strong>yq</strong> â€“ YAML lesen, bearbeiten und konvertieren â€“ <a href="https://mikefarah.gitbook.io/yq/">https://mikefarah.gitbook.io/yq/</a></li>
<li><strong>jless / yless</strong> â€“ interaktiv in JSON/YAML navigieren â€“ <a href="https://jless.io">https://jless.io</a></li>
</ul>
<p>In diesem Beitrag stelle ich euch diese Tools vor â€“ mit Beispielen, die ihr direkt in eurer eigenen Shell ausprobieren kÃ¶nnt.</p>
<hr>
<h2>jq â€“ der Klassiker fÃ¼r JSON</h2>
<p>Das vermutlich bekannteste und am weitesten verbreitete Tool fÃ¼r JSON ist <a href="https://jqlang.org"><strong><code>jq</code></strong></a>.
Es ist so etwas wie der <em>Schweizer Taschenmesser</em> fÃ¼r JSON:</p>
<ul>
<li>formatiert unlesbare Minified-JSON-Dateien,</li>
<li>extrahiert gezielt Werte,</li>
<li>filtert und transformiert Daten,</li>
<li>eignet sich fÃ¼r einmalige Ad-hoc-Analysen genauso wie fÃ¼r Skripte.</li>
</ul>
<p>Ein einfaches Beispiel: JSON schÃ¶n formatieren:</p>
<pre><code>$ cat data.json
{"user":{"id":42,"name":"Alice"},"active":true}
$ cat data.json | jq # oder `jq &lt; data.json`
</code></pre>
<div class="hll"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">42</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Alice&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;active&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="p">}</span>
</pre></div>
<p>So schnell wird aus einem unÃ¼bersichtlichen Einzeiler eine lesbare Struktur.</p>
<p>Mann kann es aber auch super in scripten verwenden um Daten aus json zu extrahieren:</p>
<div class="hll"><pre><span></span>get_current_gitlab_token<span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">    </span>kubectl<span class="w"> </span>get<span class="w"> </span>secret<span class="w"> </span><span class="nv">$SECRETNAME</span><span class="w"> </span>-n<span class="w"> </span><span class="nv">$INITIALNAMESPACE</span><span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span>
<span class="w">        </span>jq<span class="w"> </span>-r<span class="w"> </span><span class="s1">&#39;.data[&quot;.dockerconfigjson&quot;]&#39;</span><span class="w"> </span><span class="m">2</span>&gt;/dev/null<span class="w"> </span><span class="p">|</span>
<span class="w">        </span>base64<span class="w"> </span>--decode<span class="w"> </span><span class="p">|</span>
<span class="w">        </span>jq<span class="w"> </span>-r<span class="w"> </span><span class="s1">&#39;.auths[&quot;registry.gitlab.com&quot;].password&#39;</span><span class="w"> </span><span class="m">2</span>&gt;/dev/null
<span class="o">}</span>
</pre></div>
<p>Oder um in einem JSON-File Daten einzutragen:</p>
<div class="hll"><pre><span></span>kubectl<span class="w"> </span>get<span class="w"> </span>secrets<span class="w"> </span>shipa-certificates<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="se">\</span>
<span class="w">        </span><span class="p">|</span><span class="w"> </span>jq<span class="w"> </span><span class="s2">&quot;.data[\&quot;ca.pem\&quot;] |= \&quot;</span><span class="nv">$CA_CERT</span><span class="s2">\&quot;&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span><span class="p">|</span><span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>-
</pre></div>
<p><code>jq</code> kann noch viel mehr. Wer das Werkzeug noch nicht kennt sollte unbedingt ein paar Minuten investieren um <a href="https://jqlang.org/tutorial/">das Tutorial</a> querzulesen, und dann bei der nÃ¤chsten EinsatzmÃ¶glichkeit gezielt nach der Syntax schauen. Pro tip: KI's kÃ¶nnen diese Syntax prima, und <code>jless</code> (kommt gleich) kann diese auch generieren.</p>
<hr>
<h2>jo â€“ JSON in der Shell erzeugen</h2>
<p>WÃ¤hrend <code>jq</code> ideal zum Lesen und Transformieren ist, eignet sich <strong><code>jo</code></strong> perfekt, um JSON direkt in der Shell zu erstellen. Damit lassen sich Testdaten oder API-Payloads schnell zusammenbauen.</p>
<p>Ein einfaches Beispiel:</p>
<div class="hll"><pre><span></span>jo<span class="w"> </span><span class="nv">name</span><span class="o">=</span>Alice<span class="w"> </span><span class="nv">age</span><span class="o">=</span><span class="m">30</span><span class="w"> </span><span class="nv">active</span><span class="o">=</span><span class="nb">true</span>
</pre></div>
<p>Ausgabe:</p>
<div class="hll"><pre><span></span><span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;Alice&quot;</span><span class="p">,</span><span class="nt">&quot;age&quot;</span><span class="p">:</span><span class="mi">30</span><span class="p">,</span><span class="nt">&quot;active&quot;</span><span class="p">:</span><span class="kc">true</span><span class="p">}</span>
</pre></div>
<p>Auch Arrays sind mÃ¶glich:</p>
<div class="hll"><pre><span></span>jo<span class="w"> </span>-a<span class="w"> </span>red<span class="w"> </span>green<span class="w"> </span>blue
</pre></div>
<p>âœ <code>["red","green","blue"]</code></p>
<p>Verschachtelte Objekte:</p>
<div class="hll"><pre><span></span>jo<span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="k">$(</span>jo<span class="w"> </span><span class="nv">name</span><span class="o">=</span>Alice<span class="w"> </span><span class="nv">id</span><span class="o">=</span><span class="m">42</span><span class="k">)</span><span class="w"> </span><span class="nv">project</span><span class="o">=</span>Demo
</pre></div>
<p>âœ <code>{"user":{"name":"Alice","id":42},"project":"Demo"}</code></p>
<p>Das eignet sich sehr gut fÃ¼r schnelle <code>curl</code>-Requests, aber insbesondere auch fÃ¼r shell scripte in denen inline json sonst sehr schnell sehr unÃ¼bersichtlich wird:</p>
<div class="hll"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-d<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>jo<span class="w"> </span><span class="nv">username</span><span class="o">=</span>dev<span class="w"> </span><span class="nv">password</span><span class="o">=</span>secret<span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>https://example.com/api/login
</pre></div>
<hr>
<h2>yq â€“ YAML lesen und bearbeiten</h2>
<p>YAML verwenden wir Ã¼berall, am meisten habe ich in Kubernetes damit zu tun. <a href="https://mikefarah.gitbook.io/yq/"><strong><code>yq</code></strong></a> ist das Werkzeug der Wahl, um YAML-Dateien zu lesen, zu durchsuchen und zu editieren. Die Syntax ist sehr nahe an <code>jq</code>, das Werkzeug kann neben YAML aber auch JSON, TOML und XML verarbeiten, und zwischen diesesn Konvertieren. Im wesentlichen kann es das gleiche wie <code>jq</code>, eben auch fÃ¼r YAML.</p>
<hr>
<h2>jless &amp; yless â€“ interaktiv stÃ¶bern</h2>
<p>Wenn Dateien zu groÃŸ oder zu komplex werden, helfen <a href="https://jless.io"><strong><code>jless</code></strong></a> und <strong><code>yless</code></strong> (ein <code>alias yless=jless --yaml</code>. Sie bieten eine interaktive Ansicht fÃ¼r JSON und YAML â€“ mit:</p>
<ul>
<li>Syntax-Highlighting,</li>
<li>Falten und Aufklappen von Strukturen,</li>
<li>komfortabler Navigation und Suche.</li>
</ul>
<p>Beispiel:</p>
<div class="hll"><pre><span></span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-oyaml<span class="w"> </span><span class="p">|</span><span class="w"> </span>yless
</pre></div>
<p>Das schÃ¶ne: Man kann hier auf der Shell wunderbar uninteressante textblÃ¶cke einklappen um schnell die wichtigen Informationen zu fokussieren, und dann Ã¼ber Tastaturkommandos werte, oder jq/yq filter auf das aktuell ausgewÃ¤hlte Element kopieren, um das z.B. dann auf alle Pods in einem Namespace anzuwenden.</p>
<hr>
<h2>Fazit</h2>
<p>Mit diesen Tools â€“ <code>jq</code>, <code>jo</code>, <code>yq</code>, <code>jless</code> und <code>yless</code> â€“ wird das Arbeiten mit JSON und YAML auf der Shell <em>deutlich</em> angenehmer. Sehr gut investierte Zeit diese Werkzeuge (eines nach dem Anderen) zu lernen.</p>

    </section>
    
      <footer>
        <a href="2025/8/arbeiten-mit-json-and-yaml-auf-der-shell/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/8/mit-llm-rag-einfach-mal-ausprobieren-direkt-von-der-shell/">
        Mit llm RAG einfach mal ausprobieren â€“ direkt von der Shell
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-08-07">Thursday, August 7, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/8/mit-llm-rag-einfach-mal-ausprobieren-direkt-von-der-shell/workflow.png" alt="Ablaufdiagramm">
Einer der coolsten Aha-Momente der letzten Tage bei mir war, wie einfach und niederschweflig das Arbeiten mit Retrieval-Augmented Generation (RAG) von der Shell inzwischen sein kann â€“ ganz ohne spezielle Infrastruktur, Vektor-Datenbank oder Server-Backend. Das Python-Tool <a href="https://pypi.org/project/llm/"><code>llm</code></a> macht  das mÃ¶glich: RAG direkt aus der Kommandozeile, mit SQLite als Backend und einfachen Kommandos, die sich hervorragend in Shell-Workflows integrieren lassen.</p>
<h2>Ein Power Tool fÃ¼r Sprachmodelle in der Shell</h2>
<p><a href="https://llm.datasette.io/en/stable/"><code>llm</code> kann natÃ¼rlich noch viel mehr und ist ein Power Tool, das den Einsatz von KI direkt im Terminal erlaubt</a>. Es erlaubt mit beliebigen API-Providern oder lokalen Modellen zu sprechen und integriert diese damit nahtlos in eigene Skripte. Use Cases: Daten hinein pipen und mit dem LLM bearbeiten. Ob zusammenfassen, erklÃ¤ren, Ã¼bersetzen, mit einem aufwendigen Prompt aus einer Datei beackernâ€¦ Da geht so viel. Egal was Ihr aus diesem Artikel mitnehmt, zumindest sollte es sein das Ihr <code>llm</code>Â in euren Workflow aufnehmt und installiert.</p>
<h2>Der RAG-Workflow von der Shell aus</h2>
<p>Ein kompletter RAG-Workflow funktioniert mit <code>llm</code> in wenigen Schritten. <a href="https://building-with-llms-pycon-2025.readthedocs.io/en/latest/semantic-search-and-rag.html">Diese Demo hier hab ich von Simon Willison geklaut, dem Autor von <code>llm</code></a>. <a href="https://github.com/python/peps">Hier wird semantische Suche in den Python Enhancement Proposals demonstriert</a>. Dieses Tutorial verwendet einen lokalen LLM-Server, man kann das aber natÃ¼rlich auch mit GitHub Copilot oder Ã¤hnlichen Modellen machen. Herauszufinden wie die dort heiÃŸen und zu verbinden sind bleibt ein Exercise fÃ¼r den Leser.</p>
<h3>1. Dateien vorbereiten</h3>
<p>Wir erstellen gekÃ¼rzte Versionen von Textdateien:</p>
<div class="hll"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>peps-truncated
<span class="k">for</span><span class="w"> </span>f<span class="w"> </span><span class="k">in</span><span class="w"> </span>peps/*.rst<span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">  </span>head<span class="w"> </span>-c<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$f</span><span class="s2">&quot;</span><span class="w"> </span>&gt;<span class="w"> </span><span class="s2">&quot;peps-truncated/</span><span class="k">$(</span>basename<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$f</span><span class="s2">&quot;</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="k">done</span>
</pre></div>
<p>Das ist natÃ¼rlich streng genommen falsch, weil wir ganz viel Daten wegschmeiÃŸen. Einiges spricht aber trotzdem dafÃ¼r:</p>
<ol>
<li>Gerade lokale Modelle haben gerne nicht so groÃŸe Kontext-Fenster und da muss das Dokument reinpassen.</li>
<li>Meistens steht am Anfang eines Dokuments worum es geht. FÃ¼r unsere Zwecke also eine gute NÃ¤herung.</li>
</ol>
<p>Um das spÃ¤ter in ein Produkt umzuwandeln mÃ¼ssten wir uns noch weitere StrategienÂ anschauen, z.B. mit einem Sliding Window Ã¼ber die Dokumente zu gehen und fÃ¼r jeden Abschnitt ein Embedding zu erzeugen. GrundsÃ¤tzlich ist es aber eine gute Idee verschiedene Indexe zu erzeugen die unterschiedliche Zwecke erfÃ¼llen.</p>
<h3>2. Vektor-Index erstellen</h3>
<div class="hll"><pre><span></span>llm<span class="w"> </span>embed-multi<span class="w"> </span>peps<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-m<span class="w"> </span>mxbai-embed-large<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--files<span class="w"> </span>peps-truncated<span class="w"> </span><span class="s1">&#39;pep-3*.rst&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-d<span class="w"> </span>peps.db<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--store
</pre></div>
<p>Das erzeugt eine SQLite-Datenbank mit eingebetteten Vektoren. Wichtig: Die Datenbank speichert auch, mit welchem Modell die Einbettung erfolgte â€“ bei weiteren Operationen auf der gleichen Collection <code>peps</code> ignoriert <code>llm</code>Â den Modell-Parameter ohne Fehlermeldung!</p>
<p>Seiten-Notiz: Embeddings, was ist das? Ein Embedding ist eine Umwandlung von einem Text in eine Zahlenreihe (Mathematisch: Einen Vektor). Jeder dieser Vektoren beschreibt eine Koordinate in einem Hoch-Dimensionalen Raum, mit der Eigenschaft, das Koordinaten die sich Nahe sind von einem Text kommen der semantisch Ã„hnlich ist. Darin kann man sogar Rechnen, ein etwas Ã¼berstrapaziertes Beispiel wÃ¤re z.B. der Vektor fÃ¼r KÃ¶nig + Weiblich = KÃ¶nigin. <a href="https://simonwillison.net/2023/Oct/23/embeddings/">Mehr gibts hier</a></p>
<h3>3. Abfragen stellen</h3>
<div class="hll"><pre><span></span>llm<span class="w"> </span>similar<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;What do string templates look like?&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span>peps.db<span class="w"> </span>-n<span class="w"> </span><span class="m">2</span><span class="w"> </span>peps<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="p">|</span><span class="w"> </span>llm<span class="w"> </span>-s<span class="w"> </span><span class="s2">&quot;Answer the question: What do string templates look like?&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-m<span class="w"> </span>devstral<span class="w"> </span>-o<span class="w"> </span>num_ctx<span class="w"> </span>256_00
</pre></div>
<p>Hier wird erst Ã¤hnliche Inhalte zur Frage gesucht. Wichtige Details: Das Kontext-Fenster des Sprachmodells das antwortet muss groÃŸ genug sein, das es alle Antworten in seinen Kontext aufnehmen kann. Ansonsten wird gerne der Anfang abgeschnitten - und da steht natÃ¼rlich der Treffer mit dem besten Score.</p>
<h3>4. Automatisieren</h3>
<p>Wir kÃ¶nnen sogar direkt ein Skript generieren lassen:</p>
<div class="hll"><pre><span></span>llm<span class="w"> </span><span class="s1">&#39;</span>
<span class="s1">Build me a bash script like this:</span>
<span class="s1">./pep-qa.sh &quot;What do string templates look like?&quot;</span>
<span class="s1">It should first run:</span>
<span class="s1">llm similar -c $question -d peps.db peps</span>
<span class="s1">Then it should pipe the output from that to:</span>
<span class="s1">llm -s &quot;Answer the question: $question&quot; -m gpt-4.1-mini</span>
<span class="s1">That last command should run so the output is visible as it runs.</span>
<span class="s1">&#39;</span><span class="w"> </span>-x<span class="w"> </span>&gt;<span class="w"> </span>pep-qa.sh
</pre></div>
<h2>Fazit</h2>
<p>Was frÃ¼her nach viel Setup aussah (Vektor-Datenbank, Backend-API, RAG-Pipeline), ist heute in wenigen Shell-Befehlen machbar. SQLite funktioniert dabei erstaunlich gut â€“ <code>llm</code> fÃ¼hrt einfach einen Full-Table-Scan durch und berechnet die Vektor-AbstÃ¤nde direkt. Das ist nicht hyper-skalierbar, aber bis 10.000 bis 100.000 EintrÃ¤ge durchaus brauchbar.</p>
<p>Und das Beste: <code>llm</code> lÃ¤sst sich Ã¼berall in bestehende Shell-Skripte und Workflows einbauen â€“ sogar mit piped Input. Wer also mal eben eine intelligente Suche oder ein Sprachmodell in seinen CLI-Workflow integrieren will, findet hier ein extrem mÃ¤chtiges Toolset.</p>
<p>Ich kann nur empfehlen ein Shell-Werkzeug wie <code>llm</code>Â zu lernen.</p>

    </section>
    
      <footer>
        <a href="2025/8/mit-llm-rag-einfach-mal-ausprobieren-direkt-von-der-shell/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/7/devopscon-keynote-security-ist-jetzt-teil-von-devops/">
        DevOpsCon Keynote â€“ Security ist jetzt Teil von DevOps?
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-07-30">Wednesday, July 30, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/7/devopscon-keynote-security-ist-jetzt-teil-von-devops/secure-chips.png" alt="Metapher auf Teams die jeweils Sicherheits-Interessierte enthalten, die einfach von Spezialisten UnterstÃ¼tzung erhalten kÃ¶nnen"></p>
<p>Ich konnte auf der DevOpsCon der Keynote "From Static to Strategic: Reimagining Application Security for a DevOps World" von John D. Wood nicht entgehen. Um ehrlich zu sein: Die Keynote hat mich nicht begeistert. Am ehesten noch fand ich interessant das er Zahlen hatte, das die meisten SicherheitslÃ¼cken (auch nach Bekanntwerden) noch Ã¼ber ein Dreiviertel-Jahr offen sind. Aua. Ein Satz am Ende ist bei mir hÃ¤ngengeblieben:</p>
<blockquote><p>"DevOps bekommt jetzt auch Security."</p>
</blockquote>
<p>Was simpel klingt, ist in der RealitÃ¤t alles andere als einfach â€“ und betrifft uns ganz konkret. In einer Zeit, in der wir als Unternehmen KRITIS-relevant geworden sind, ist es fÃ¼r viele Risiken nicht mehr mÃ¶glich sie einfach zu Ã¼bernehmen (AKA aussitzen). Wir mÃ¼ssen sie aktiv mitigieren â€“ und das gilt besonders auch fÃ¼r Security-Risiken.</p>
<h3>Security: Aus DevOps wird "DevSecOps"?</h3>
<p>Dev ist schon schwer. Ops noch schwieriger. Und jetzt kommt Security obendrauf. Nicht jedes Team kann oder will alle drei Disziplinen gleich gut abdecken. Und dennoch ist klar: Es kommt mehr Arbeit auf uns zu.</p>
<p>Wir werden bei bestimmten Anwendungen in Zukunft viel stÃ¤rker darauf achten mÃ¼ssen:</p>
<ul>
<li>Dass Betriebssysteme (in Docker-Containern) aktuell sind,</li>
<li>Dass ProjektabhÃ¤ngigkeiten regelmÃ¤ÃŸig gepflegt werden,</li>
<li>Dass wir verstehen, <em>welche SicherheitslÃ¼cken fÃ¼r <strong>uns</strong> relevant</em> sind â€“ nicht nur, weil ein Scanner sie anmeckert, sondern weil unsere eigene RisikoabwÃ¤gung sie als kritisch einstuft.</li>
</ul>
<h3>Wunsch-Szenario: Expertise teilen, nicht duplizieren</h3>
<p>Mein Wunsch wÃ¤re, dass nicht jedes Team die komplette Security-Expertise selbst aufbauen muss. Stattdessen sollten sich diejenigen, die sich besonders fÃ¼r das Thema interessieren, tiefer einarbeiten kÃ¶nnen â€“ und jederzeit unkompliziert Zugang zu  Spezialist\:innen haben. Idealerweise entsteht daraus eine Art Mentoring-Beziehung.</p>
<p>Das Ziel: Schnell und unbÃ¼rokratisch Expertise bekommen, wenn man merkt, dass man sie braucht. Entwickler\:innen sollen lernen, Security-relevante Situationen zu erkennen und wissen, wo sie gezielt und niederschwellig UnterstÃ¼tzung finden.</p>
<h3>Compliance-Checkbox oder echte Verteidigung?</h3>
<p>Ein starkes Bild aus dem Vortrag war die Kritik an klassischen Security-Prozessen: WÃ¶chentliche Scans, lange Backlogs mit offenen CVEs, endlos False Positives, wenig konkreter Nutzen. All das erzeugt ungeplante Arbeit, und widerspricht damit dem DevOps-Grundsatz "No unplanned work" â€“ und hilft im Ernstfall wenig. Letztlich mÃ¼ssen wir ja die Daten unserer Versicherten SchÃ¼tzen, dass der Bug den ein Angreifer bei uns AusgenÃ¼tzt hat schon lange bekannt war, hilft uns nicht weiter.</p>
<h3>Fazit</h3>
<p>Ich nehme aus dem Talk vor allem eines mit: Security kÃ¶nnen wir in Zukunft nicht lÃ¤nger als "Problem von jemand anderem" verstehen. Sie ist jetzt (oder wird es bald) integraler Teil von DevOps â€“ ob uns das passt oder nicht.</p>
<p>Und wir mÃ¼ssen Wege finden, wie wir das <em>gemeinsam</em> schultern kÃ¶nnen â€“ weil wir eben nicht jeden Entwickler zum Security-Experten machen kÃ¶nnen.</p>

    </section>
    
      <footer>
        <a href="2025/7/devopscon-keynote-security-ist-jetzt-teil-von-devops/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/7/die-bittere-realitaet-container-sicherheit-ist-kaputt/">
        Die bittere RealitÃ¤t: Container-Sicherheit ist Kaputt
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-07-16">Wednesday, July 16, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/7/die-bittere-realitaet-container-sicherheit-ist-kaputt/chainguard-cve-history.png" alt="Container Security">
Vor einigen Wochen war ich auf der DevOpsCon in Berlin. Einer der spannenderen  VortrÃ¤ge war fÃ¼r mich: <strong>"Supply Chain Security and the real world: Lessons from Incidents"</strong>. Offiziell ging es um Sicherheit in Container-Umgebungen. Inoffiziell war es eine Abrechnung mit dem Chaos, das wir im Alltag mit Docker-Containern erleben.</p>
<p>Wir alle lieben Docker Hub: Schnell ein Image ziehen, starten, fertig. Aber was dabei oft vergessen wird: Selbst die als "offiziell" markierten Container bieten keinerlei Garantien. Weder Ã¼ber die AktualitÃ¤t noch Ã¼ber Sicherheit. Fast alle dieser Container werden monatelang nicht aktualisiert, obwohl es CVEs fÃ¼r enthaltene Komponenten gibt.</p>
<p>Wenn man das ernst nimmt, mÃ¼sste man:</p>
<ul>
<li>Alle Container regelmÃ¤ÃŸig selbst neu bauen und dabei Updates der darin enthaltenen Distributionen installieren</li>
<li>Bei jeder AbhÃ¤ngigkeit Ã¼berwachen, ob es CVEs oder Updates gibt</li>
<li>Die Upstream-Projekte verstehen, ihre Update-KanÃ¤le abonnieren</li>
<li>Alle Dockerfiles durchdringen (insbesondere bizarr manuell installierter Binaries)</li>
</ul>
<p>Kurz: Wer Container sicher betreiben will, muss eigentlich selbst zur Distribution werden.</p>
<h3>Die LÃ¶sung: "Start Left" statt "Shift Left"</h3>
<p>Die Firma <strong>Chainguard</strong> hat in dem Vortrag ihre Alternative vorgestellt: Ein Repository von sicherheitsoptimierten, rootlosen Containern, die alle:</p>
<ul>
<li><strong>ohne bekannte CVEs</strong> ausgeliefert werden</li>
<li>auf einem selbstgebauten, deterministischen OS basieren ("Wolfi", im wesentlichen Alpine mit GLibC statt Musl)</li>
<li>reproduzierbar gebaut werden (jede\:r kann sie nachbauen, wenn auch nicht Bit fÃ¼r Bit)</li>
<li>mit Software-Bill-of-Materials (SBOM) ausgeliefert werden</li>
<li>Auch im Container als normale Nutzer ausgefÃ¼hrt werden anstatt als `root`</li>
<li>und bei neuen Upstream-Vulnerabilities innerhalb von 7 Tagen gepatcht werden</li>
</ul>
<p>Die Container sind FIPS-kompatibel, in zwei Varianten (Production vs.Â Dev - mit mehr Tools) verfÃ¼gbar und mit bekannten Tools wie <code>trivy</code> problemlos scannbar. Offen Statistiken zeigen beeindruckend wie <em>viel weniger CVEs</em> sieh in Ihren Containern haben. NÃ¤mlich in der Regel gar keine.</p>
<h3>Warum das fÃ¼r viele ein Game-Changer sein kÃ¶nnte</h3>
<p>Wie in vielen Unternehmen, ist auch bei uns die Nutzung von Docker-Containern ein "Free for All": Jeder zieht, was er braucht, hauptsache es lÃ¤uft. Sicherheitsrichtlinien? Nicht vorhanden. Updates? Machen wir Manuell alle Jubeljahre. Genau hier setzen die Container von Chainguard (oder auch Dockers eigene "Hardened Images") an:</p>
<p>Man kÃ¶nnte sagen:</p>
<blockquote><p>Was sonst niemand zuverlÃ¤ssig macht, macht ChainGuard automatisch.</p>
</blockquote>
<p>Und das Beste: Die Basis-Container sind sogar kostenlos (und damit z.B. auch fÃ¼r Open Source Projekte) verwendbar. Damit kann man ohne groÃŸen Aufwand den Produktivbetrieb auf eine wesentlich sicherere Basis stellen.</p>
<p>Gerade wenn man â€“ wie bei KRITIS-Vorgegeben â€“ innerhalb eines festen Zeitrahmens Sicherheitsupdates einspielen muss, ist eine verlÃ¤ssliche Update-Garantie Gold wert.</p>
<h3>Mein Fazit</h3>
<p>Container sind kein Selbstzweck â€“ und sie haben einen groÃŸen Nachteil gegenÃ¼ber VerÃ¤nderbarer Infrastruktur: Man verliert die automatisch installierten Updates der Linux Distributionen. Wer diesen Aufwand nicht selbst stemmen will, braucht Alternativen. Die gehÃ¤rteten Container von ChainGuard oder Docker sind ein vielversprechender Weg, um  mit minimalem Aufwand viel weniger CVEs und fehlender Updates, sowie weit mehr Transparenz gewinnen kann.</p>
<p>Probiert es doch mal aus. Ich wÃ¼rde mich sehr Ã¼ber Feedback freuen wo die Grenzen und Probleme dieses Ansatzes liegen. Offensichtlich ist schon mal, dass dort nicht so viele Container gibt.</p>
<p>GrundsÃ¤tzlich aber immer: Bitte Entscheidet euch bewusst fÃ¼r Images, die gepflegt werden. Und nicht fÃ¼r das erste, das die Suche auf Docker Hub zurÃ¼ck gibt.</p>

    </section>
    
      <footer>
        <a href="2025/7/die-bittere-realitaet-container-sicherheit-ist-kaputt/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/6/nuetzliche-shell-kommandos-sort-uniq/">
        NÃ¼tzliche Shell-Kommandos: sort, uniq
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-06-25">Wednesday, June 25, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/6/nuetzliche-shell-kommandos-sort-uniq/set-operations.png" alt="Set Operations">
Weil ich es heute wiederholt nachschlagen musste, hier noch eine Erinnerung an mich selbst, wie einfach es ist auf der Shell set Operationen durchzufÃ¼hren.</p>
<p>In unserem Beispiel: ~10k Datenbank-IDs hier, ~15k Datenbank-IDs da, und die Frage welche davon nur in der einen Liste enthalten sind. Das ist dann einfach zu beantworten, wenn man die auf eine ID pro Zeile ausgibt, und dann einfach mit <code>set_difference</code> bearbeitet.</p>
<div class="hll"><pre><span></span>set_union<span class="w"> </span><span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq
<span class="o">}</span>

set_intersection<span class="w"> </span><span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>--repeated
<span class="o">}</span>

set_difference<span class="w"> </span><span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>--unique
<span class="o">}</span>

set_symmetric_difference<span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>--unique
<span class="o">}</span>
</pre></div>
<p><a href="https://stackoverflow.com/a/13038235/4572750">Quelle</a></p>

    </section>
    
      <footer>
        <a href="2025/6/nuetzliche-shell-kommandos-sort-uniq/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/6/devopscon-stolperfallen-beim-aufbau-interner-developer-platforms-idp/">
        DevOpsCon: Stolperfallen beim Aufbau interner Developerâ€¯PlatformsÂ (IDP)
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-06-19">Thursday, June 19, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p>Heute gibts den Start meines Berichts von der DevOpsCon 25. So viel allgemeines vorweg: War schÃ¶n.  Druckbetankung wie es sich gehÃ¶rt.</p>
<p>Los ging es mit einer Keynote Ã¼ber interne Entwickler-Plattformen und was dabei gerne schief geht.</p>
<h2>1â€¯|â€¯Reality-Check: 90 % der Devs nutzen schon eine IDP â€“ wir auch</h2>
<ul>
<li>Laut Jessica arbeiten rundâ€¯90â€¯% aller Entwickler:innen mittlerweile mit einer internen Plattform â€“ oft, ohne es zu merken.</li>
<li>Wir auch? Was ist unsere Plattform?</li>
</ul>
<h2>2â€¯|â€¯Das theoretische Fundament</h2>
<p>Jessica empfahl <em>vier BÃ¼cher</em>, die jede:r Platformâ€‘Builder kennen sollte. (Lustigerweise gab Sie zu, das Sie selbst noch nicht alle davon gelesen komplett gelesen hat.)</p>
<table>
<thead><tr>
<th>Buch</th>
<th>Kernaussage fÃ¼r IDP</th>
<th>Mein Takeâ€‘away</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="https://www.amazon.com/Transformed-Becoming-Product-Driven-Company-Silicon/dp/1119697336">Transformed</a></strong></td>
<td>Von Silos zu <strong>empowereden Produktâ€‘Teams</strong></td>
<td>Auch Plattformâ€‘Teams brauchen Produktdenken und Produkt-Manager.</td>
</tr>
<tr>
<td><strong><a href="https://www.amazon.com/Team-Topologies-Organizing-Business-Technology/dp/1942788819">Team Topologies</a></strong></td>
<td><strong>Teamâ€‘Typen &amp; Schnittstellen</strong> (u.â€¯a. Platform &amp; Enabling Teams)</td>
<td>Klingt sehr Ã¤hnlich zu dem wie wir organisiert sind. Unterschiede: Komplizierte Subsysteme brauchen eigene Teams. Enablingâ€‘Teams sind hier fast immer <strong>temporÃ¤r</strong>.</td>
</tr>
<tr>
<td><strong><a href="https://www.amazon.de/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">Accelerate</a></strong></td>
<td>Deployâ€‘Freq., Leadâ€‘Time, Failureâ€‘Rate, MTTR</td>
<td><a href="https://dora.dev/guides/dora-metrics-four-keys/">DORAâ€‘Scores</a> = Proxy fÃ¼r Platform-Teamâ€‘Erfolg. Nugget: Im Raum war niemand der alle 4 Metriken einsetzt, oder jemanden kennt der das tutâ€¦</td>
</tr>
<tr>
<td><strong><a href="https://www.amazon.de/Platform-Engineering-Technical-Product-Leaders/dp/1098153642">Platform Engineering</a></strong></td>
<td><strong>Plattform ersetzt Glueâ€‘Code</strong> &amp; schafft Selfâ€‘Service</td>
<td>Eine IDP ist <strong>Software</strong>, kein Opsâ€‘Team.</td>
</tr>
</tbody>
</table>
<h2>3â€¯|â€¯Typische Fallstricke</h2>
<ol>
<li><strong>Menschen im Plattform-Team bringen ihre Erfahrungen mit</strong><ul>
<li>â€Itâ€™s faster if I just do it.â€œ Sorgt gerne dafÃ¼r das das Ergebnis auch nur Sie benutzen kÃ¶nnen.</li>
<li>Damit erzeugt man ein neues Ops-Silo. Dringend zu vermeiden. Das Ziel ist, das andere Teams sich selbst helfen kÃ¶nnen.</li>
</ul>
</li>
<li><strong>Rudis Resterampe</strong> (ScopeÂ Creep)<ul>
<li>Plattformâ€‘Team sammelt alles, was sonst niemand machen will.</li>
<li>Konsequenz: Keine Zeit mehr fÃ¼r strategische Funktionen.</li>
<li>Braucht eine klare Vision, und insbesondere By-In von Leadership. Dann Iterationen und viel Kommunikation.</li>
</ul>
</li>
<li><strong>Alles sofort lÃ¶sen wollen (Rudis Resterampe 2.0)</strong><ul>
<li>Minimalismus ist KingÂ ğŸ‘‘. Nicht jedes Problem muss gleich gelÃ¶st werden.</li>
<li>Priorisiere <strong>Onboarding, Selfâ€‘Service &amp; Empowerment</strong>.</li>
</ul>
</li>
<li><strong>Das falsche Problem LÃ¶sen</strong><ol>
<li>Es ist sehr einfach das falsche Problem zu lÃ¶sen. SchlieÃŸlich sind wir alle Entwickler und wissen was wir brauchen.</li>
<li>Aber jedes Team ist anders und hat andere Aufgaben. Daher ist es unglaublich wichtig mit den Menschen intensiv zu sprechen die man beglÃ¼cken will.</li>
<li>Plattform-Engineering braucht genauso Produkt-Management und einen Produkt-Manager wie andere Themen. Wenn das Budget dafÃ¼r nicht vorhanden ist, muss man diese Aufgaben trotzdem erfÃ¼llen.</li>
</ol>
</li>
<li><strong>Plattformâ€‘Migrationen unterschÃ¤tzen</strong><ul>
<li>Jede Migration ist Schmerzhaft undÂ <strong>kostet Vertrauen</strong> (Vertrauen ist wie eine WÃ¤hrung. Wenn man es ausgegeben hat, ists wech).</li>
<li>Daher so wenig Migrationen wie mÃ¶glich, und diese gut vorbereiten, auch wenn es viel Aufwand erzeugt.</li>
<li>Ziel: <strong>Automatisierte, Lowâ€‘Impactâ€‘Migrationspfade</strong>.</li>
</ul>
</li>
</ol>
<h2>4â€¯|â€¯Fragen an den Leser</h2>
<ol>
<li><strong>Was ist deine aktuelle Plattform?</strong></li>
<li><strong>Wo klemmt es eigentlich derzeit?</strong></li>
<li><strong>Macht es Sinn die DORAâ€‘Baselines zu</strong> messen?</li>
</ol>
<h2>5â€¯|â€¯Fazit</h2>
<p>Ein internes Developerâ€‘Platformâ€‘Team ist <strong>kein Sonderâ€‘Opsâ€‘Team</strong>, sondern ein <strong>Produktâ€‘Team</strong> mit klarer Vision, fokussiertem Scope und messbarem Impact.
Je einfacher, desto besser â€“ und Vertrauen ist kostbar.</p>
<blockquote><p><em>â€Minimalismus ist King â€“ lÃ¶se die wichtigsten 20â€¯% zuerst, die den Teams 80â€¯% des Schmerzes nehmen.â€œ</em> â€“ Jessicaâ€¯Anderson</p>
</blockquote>

    </section>
    
      <footer>
        <a href="2025/6/devopscon-stolperfallen-beim-aufbau-interner-developer-platforms-idp/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/5/die-freuden-einer-gut-eingerichteten-shell-fzf/">
        Die Freuden einer gut eingerichteten Shell: fzf
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-05-07">Wednesday, May 7, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/5/die-freuden-einer-gut-eingerichteten-shell-fzf/fzf.png" alt="fzf"></p>
<p>Nachdem es bisher in <a href="../../categories/code/">der Serie</a> um die <a href="../../blog/2024/11/grundlegende-funktionen-und-einstellungen-des-terminals/">grundlegende Einrichtung der Shell</a>, <a href="../../blog/2025/2/die-freuden-einer-gut-eingerichteten-shell-prompt/">einen guten Prompt</a> und <a href="../../blog/2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/">funktionierende autoomatische VervollstÃ¤ndigung</a> ging, geht es jetzt eine Weile um Werkzeuge um mit der Shell effizient zu navigieren und Dateien und Inhalte zu finden.</p>
<h2>Einleitung</h2>
<p>Hier geht es mir darum das die Arbeit auf der Shell (auf dem eigenen Rechner vor allem) nur dann schnell und Effizient ist, wenn man schnel und einfach in die Ordner kommt in denen man arbeiten mÃ¶chte, und die Dateien findet in denen etwas interessantes steht das man entweder lesen oder verÃ¤ndern mÃ¶chte.</p>
<p>Und natÃ¼rlich ist das Skillset auch auf beliebige Server transferierbar, weil man alle diese Werkzeuge (oder deren etwas primitivere Variante, dazu spÃ¤ter mehr) auch auf einem Server, oder in einem Docker-Container, gerne auch auf einem Kubernetes-Cluster in Produktion einsetzen kann, wo man sonst halt nicht so viele Werkzeuge hat, und schon gar nicht seine IDE anschlieÃŸen kann um zu versuchen dort Herr der Lage zu werden.</p>
<p>Dazu mÃ¶chte ich euch die Tools <a href="https://github.com/ajeetdsouza/zoxide">zoxide</a>, grep/<a href="https://github.com/BurntSushi/ripgrep">ripgrep</a>, <a href="https://github.com/junegunn/fzf">fzf</a>, less/cat/<a href="https://github.com/sharkdp/bat">bat</a> und <a href="https://direnv.net">direnv</a> vorstellen.</p>
<p>Diese Tools erleichtern viele tÃ¤glich oft wiederholte ArbeitsablÃ¤ufe dramatisch, und sie ermÃ¶glichen viele Use-Cases, die viele grafischen IDEs und Text-Editoren gar nicht unterstÃ¼tzen. Los geht es mit dem flauschigsten der Tools, fzf.</p>
<h2>Zackig die richtige Datei finden: fzf</h2>
<p><a href="https://github.com/junegunn/fzf">fzf</a> frei Eingezangendeutscht "der flauschige Kommandozeilen Finder", ist ein werkzeug um Dateien (aber auch beliebige andere Dinge) anhand von teilen des Namens oder Mustern wie jeder erste Buchstabe der WÃ¶rter ihres Namens zu finden. Dazu bietet dieses Werkzeug eine OberflÃ¤che die interaktiv die Liste der AuswahlmÃ¶glichkeiten filtert wÃ¤hrend man tippt. Die meisten IDEs bieten so eine Funktion irgendwo mehr oder weniger gut versteckt an, und dieses Werkzeug portiert diese FunktionalitÃ¤t als generisches Werkzeug in die Shell.</p>
<p>Als beispiel: Ich mÃ¶chte einen bestimmten UnitTest ausfÃ¼hren:</p>
<div class="hll"><pre><span></span>$<span class="w"> </span>bin/run_tests_in_docker.sh<span class="w"> </span><span class="k">$(</span>fzf<span class="k">)</span>
</pre></div>
<p>Mit diesem Kommando, wird zuerst fzf aufgerufen (wegen <code>$(fzf)</code>) was dann eine oberflÃ¤che prÃ¤sentiert, mit der man interktiv die richtige oder die richtigen Dateien auswÃ¤hlen kann.</p>
<div class="hll"><pre><span></span><span class="c"># ich verwende die fish shell, daher brauch ich das $ nicht</span>
â¯ bin/run_tests_in_docker.sh <span class="o">(</span>fzf<span class="o">)</span>
  src/models/dokumente/tests/document_distribution_test.py
  src/controller/process_distribution/tests/models_test.py
  src/models/dokumente/tests/dokumente_test.py
  src/integration/d3/api/test/models_test.py
â–Œ src/models/tests/kontaktdaten_test.py
  5/448 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
<span class="o">&gt;</span> models <span class="err">&#39;</span><span class="k">test</span>.py
</pre></div>
<p>In dem Interface kann man auch mit den Pfeiltasten navigieren, oder einen Eintrag anklicken. Der von mir eingegebene Suchstring "models 'test.py" bedeutet, dass 'models' irgendwo in dem Treffer diese Buchstaben in dieser Reihenfolge vorkommen mÃ¼ssen, wÃ¤hrend "'test.py" erzwingt das der exakte String 'test.py' vorkommen muss.</p>
<p><a href="https://junegunn.github.io/fzf/shell-integration/">Wenn man die fzf-Integration mit der eigenen Shell aktiviert</a>, kriegt man viele weitere Integrationen in die Shell dazu. Zwei Beispiele:</p>
<ul>
<li><p><code>âŒƒ-T</code> sucht (mit Vorschau!) nach Dateien unterhalb des aktuellen Verzeichnisses. Das ist immer dann Praktisch wenn man fÃ¼r ein Kommando eine Datei aus dem aktuellen Projekt als Argument Ã¼bergeben muss, und spart das tippen von <code>$(fzf)</code>. Klar, mit Auto-VervollstÃ¤ndigung kommt man auch ans Ziel, aber das ist <em>soo</em> viel schneller. Insbesondere wenn man nicht genau im Kopf hat wo die Datei liegt, aber noch weiÃŸ was in Ihrem Namen oder Pfad vorkommen muss. Das verwende ich die ganze Zeit.</p>
</li>
<li><p><code>âŒƒ-R</code> sucht mit <code>fzf</code> in der Shell-Historie. Das funktioniert viel besser als die Standard-Suche, die nur nach direkt zusammenhÃ¤ngenden Buchstaben suchen kann. Ein Beispiel: Das Wenn ich das Kommando <code>helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml | yq</code> aus meiner historie suchen mÃ¶chte, mÃ¼sste ich ohne <code>fzf</code> den exakten Text schreiben der in dem Kommando vorkommt.</p>
</li>
</ul>
<div class="hll"><pre><span></span>~
Search History&gt; helmtemplateexten
  76/32637 <span class="o">(</span>0<span class="o">)</span>
  02-17 18:07:03 â”‚ helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml
  02-17 18:06:10 â”‚ helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml <span class="o">|</span> yq
  02-17 17:59:53 â”‚ helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
  02-17 20:22:18 â”‚ helm template  extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml
  02-17 18:15:27 â”‚ helm template --debug extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml
  02-17 17:59:42 â”‚ helm template --dry-run --debug extensions ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
â–Œ 02-17 17:59:29 â”‚ helm template --dry-run --debug  ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
  02-17 17:59:36 â”‚ helm template --dry-run --debug foo ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ helm template --dry-run --debug ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
</pre></div>
<p>Wenn ich oft, wenn ich ein neues Terminal Ã¶ffne in die gleichen Projekte navigiere, dann geht das prima Ã¼ber die Shell-History:</p>
<div class="hll"><pre><span></span>â¯ <span class="c"># ctrl-r fÃ¼r history suche</span>
Search History&gt; cdmkkapi
  352/32638 <span class="o">(</span>0<span class="o">)</span> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  08-12 11:56:19 â”‚ <span class="k">cd</span> mkk/api
  08-24 19:05:13 â”‚ <span class="k">cd</span> ../mkk/api
â–Œ 05-26 08:39:19 â”‚ <span class="k">cd</span> Code/Projekte/mkk/api
  07-29 17:02:48 â”‚ <span class="k">cd</span> Code/Projekte/mkk/api_infra/
  02-15 08:37:01 â”‚ <span class="k">cd</span> Code/Projekte/mkk/api_infra/monitoring/
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ <span class="k">cd</span> Code/Projekte/mkk/api â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
</pre></div>
<p>Mit <a href="https://github.com/ajeetdsouza/zoxide">Zoxide</a> geht das noch besser, aber dazu spÃ¤ter mehr.</p>
<p>So habe ich meine fzf Integration konfiguriert:</p>
<div class="hll"><pre><span></span><span class="c"># configure key-bindings for fzf-fish</span>
<span class="c"># ctrl-f directory search</span>
<span class="c"># ctrl-r history search</span>
<span class="c"># ctlr-v variables search</span>
<span class="c"># ctrl-l git log search</span>
<span class="c"># ctrl-s git status search</span>
<span class="c"># ctrl-p processes pid search</span>
fzf_configure_bindings --git_log<span class="o">=</span><span class="se">\f</span> --directory<span class="o">=</span><span class="se">\c</span>F --git_status<span class="o">=</span><span class="se">\c</span>S --processes<span class="o">=</span><span class="se">\c</span>P
</pre></div>
<p>Das geniale an fzf ist, dass es sich so wunderbar in andere Tools integrieren lÃ¤sst. Hat man es installiert wird es z.B. von <a href="https://github.com/ahmetb/kubectx">KubeCTX</a> verwendet um in <code>kubectx</code> die liste der verbundenen Kubernetes Cluster zu filtern. Oder von <code>kubens</code> um die Liste der Namespaces. TatsÃ¤chlich verwenden viele Werkzeuge intern <code>fzf</code> wenn es instaliert ist. FÃ¼r mich immer wieder eine schÃ¶ne Ãœberrachung, wenn ein weiteres Werkzeug das ich gerne einsetze <code>fzf</code> verwendet.</p>

    </section>
    
      <footer>
        <a href="2025/5/die-freuden-einer-gut-eingerichteten-shell-fzf/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/">
        Die Freuden einer gut eingerichteten Shell: Autocomplete
        </a>
      </h2>
      <p class="meta">
        written by Martin HÃ¤cker on <time datetime="2025-04-14">Monday, April 14, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <h2>Was ist schlechte VervollstÃ¤ndigung?</h2>
<p>Um zu verstehen was ich mit guter Auto-Completion fÃ¼r Shells meine, brauchen wir erst einmal eine Baseline wie eine schlechte Completion aussieht. Das lÃ¤sst sich sehr gut mit Docker demonstrieren:Â </p>
<div class="hll"><pre><span></span>docker<span class="w">Â </span>run<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--hostname<span class="w"> </span>shell-completion-demo<span class="w"> </span>debian
</pre></div>
<p>Erstes Experiment: <code>lsâ‡¥â‡¥</code> (kein Leerzeichen vor den Tabs!)</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-commands-unconfigured.png" alt="Automatische VervollstÃ¤ndigung von Kommandos - unkonfiguriert"></p>
<p>Zeigt alle Kommandos die mit <code>ls</code> anfangen
Zweites Experiment: <code>ls â‡¥â‡¥</code>
Das zeigt bei mir:</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-files-unconfigured.png" alt="Automatische VervollstÃ¤ndigung von Dateien - unkonfiguriert"></p>
<p>Schon mal gut, denn hier werden die Dateien im aktuellen Ordner vervollstÃ¤ndigt.</p>
<p>NÃ¤chste Schwierigkeitsstufe - kurze und lange Optionen: <code>ls -â‡¥â‡¥</code> (Minus vor dem Tab)
Das zeigt hier nichts, genauso fÃ¼r lange OptionenÂ <code>ls --â‡¥â‡¥</code> (zwei mal Minus vor dem Tab)</p>
<p>Keine Ausgabe. <code>ls</code> ist eigentlich so ungefÃ¤hr dasÂ einfachste Programm das jeder Shell beiliegt. Wenn automatische VervollstÃ¤ndigung also irgend etwas kann, dann sollte <code>ls</code> gut funktionieren.</p>
<h2>Was ist gute VervollstÃ¤ndigung?</h2>
<p>Dagegen mal ein Beispiel von meinem System:</p>
<p><code>lsâ‡¥</code> zeigt die Kommandos die mit ls anfangen, mit einer Kurzbeschreibung was diese Kommandos tun.</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-commands-configured.png" alt="VervollstÃ¤ndigung von Kommandos mit der Fish-Shell"></p>
<p>Schon mit einem Tab sehe ich die Dateien, und zusÃ¤tzlich sehe ich als Vorschlag den letzten Befehl den ich mit <code>ls</code> abgesetzt habe und kann diesen mit <code>âŒƒâ†’</code> im ganzen, oder mit  <code>â†’</code> wortweise akzeptieren kann.</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-files-configured.png" alt="Automatische VervollstÃ¤ndigung von Dateien mit der Fish Shell"></p>
<p>Ein ls -â‡¥<code>ergibt sofort eine Optionsliste - kurz und lang - mit einer Kurzbeschreibung was dieses Schalter tun. Ein zweites Minus und Tab</code>ls --â‡¥` zeigt nur noch die langen Optionen an:</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-options-configured.png" alt="VervollstÃ¤ndigung von Optionen mit der Fish-Shell">
<img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-long-options-configured.png" alt="VervollstÃ¤ndigung von langen Optionen mit der Fish-Shell"></p>
<p>NatÃ¼rlich kann ich mit den Pfeiltasten oder mit Tab eine der Optionen auswÃ¤hlen - natÃ¼rlich mit ordentlichem Highlighting.
So macht arbeiten auf der Shell SpaÃŸ!</p>
<p>Falls Ihr verwirrt seid das mein ls andere Optionen anbietet als eures, dann liegt das daran <a href="https://github.com/ogham/exa">das ich ls durch exa ersetzt habe</a>.</p>
<h2>Wie kÃ¶nnt Ihr das bei euch nutzen?</h2>
<p>Ich nutze die <a href="https://fishshell.com">Fish-Shell</a>, da diese von Haus aus eine sehr gute Autocompletion anbietet. Das ist aber nicht fÃ¼r jede, denn die Syntax der Fish Shell ist etwas anders als bei Bash/ZSH - eben nicht posix kompatibel. Ich mag das Weil es logischer und KÃ¼rzer ist, aber ich komme auch nicht durcheinander mit den verschiedenen Shell-Syntaxen da ich sie schon so lange verwende.</p>
<p>Fast alle Shell Konfigrurations-Frameworks wie <a href="https://ohmyz.sh">oh-my-zsh</a> oder <a href="https://github.com/sorin-ionescu/prezto">Prezto</a> bieten zumindest etwas an das diesem Nahe kommen. Alle automatische Konfiguration stÃ¶ÃŸt aber irgendwann an Ihre Grenzen wenn es um die Kommandos geht, die wir tÃ¤glich benutzen. <code>docker</code> vervollstÃ¤ndigt dann nicht compose und oder kennt die Unterkommandos davon nicht oder nur unvollstÃ¤ndig, kubectl und helm sind notorische Kandidaten fÃ¼r die man sich selber kÃ¼mmern muss.</p>
<p>Jetzt kÃ¶nnte man natÃ¼rlich versuchen automatisch aus der Hilfsausgabe dieser Kommandos etwas zu generieren (das macht z.B. die Fish shell von sich aus) oder man schreibt selber etwas (argh).</p>
<p>Oder man wendet sich vertrauensvoll an das tool <a href="https://github.com/carapace-sh/carapace">carapace</a>, mit dem man die Completion fÃ¼r Programme komfortabel fÃ¼r alle Shells nachrÃ¼sten kann. Als Beispiel um die die Autocompletions fÃ¼r kubectl nachzurÃ¼sten, einfachÂ <code>source &lt;(carapace kubectl zsh)</code> oder <code>carapace kubectl fish | source</code> (je nach shell) eingeben und ausprobieren ob es gefÃ¤llt, und wenn ja, diese Zeile in die User-Konfiguration deiner shell eintragen und viel glÃ¼cklicher sein.</p>
<p>Obacht: Man kann mit so einem Snippet</p>
<div class="hll"><pre><span></span><span class="c1"># ~/.zshrcÂ </span>
<span class="nb">export</span><span class="w"> </span><span class="nv">CARAPACE_BRIDGES</span><span class="o">=</span><span class="s1">&#39;zsh,fish,bash,inshellisense&#39;</span><span class="w">Â </span><span class="c1"># optional</span>
zstyle<span class="w"> </span><span class="s1">&#39;:completion:*&#39;</span><span class="w"> </span>format<span class="w"> </span><span class="s1">$&#39;\e[2;37mCompleting %d\e[m&#39;</span>
<span class="nb">source</span><span class="w"> </span>&lt;<span class="o">(</span>carapace<span class="w"> </span>_carapace<span class="o">)</span>
</pre></div>
<p>in seinerÂ Shell-Konfiguration alle completer des Carapace Projekts aktivieren. Das hat mir allerdings nicht gefallen,, da ich manche der eingebauten Completer der Fish-Shell noch etwas besser finde als das was Carapace bereit stellt. Aber um LÃ¼cken zu ergÃ¤nzen? Perfekt!</p>
<p>Meine Shell-Completion Konfiguration (fish!) sieht daher so aus:</p>
<div class="hll"><pre><span></span><span class="c"># enable shell completions</span>
<span class="k">set</span> --global --export CARAPACE_BRIDGES <span class="s1">&#39;zsh,fish,bash,inshellisense&#39;</span>
<span class="c"># I didn&#39;t have much luck enabling all carapace completions, but I do like some of them - especially if there is no built in fish completion for them</span>
<span class="c"># carapace _carapace | source</span>
carapace fd <span class="o">|</span> <span class="nb">source</span>
carapace bat <span class="o">|</span> <span class="nb">source</span>
carapace brew <span class="o">|</span> <span class="nb">source</span>
carapace rg <span class="o">|</span> <span class="nb">source</span>
carapace docker <span class="o">|</span> <span class="nb">source</span>
uv generate-shell-completion <span class="nb">fish</span> <span class="o">|</span> <span class="nb">source</span>
yq completion <span class="nb">fish</span> <span class="o">|</span> <span class="nb">source</span>
</pre></div>

    </section>
    
      <footer>
        <a href="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/">weiterlesenâ€¦</a>
      </footer>
    
  </article>

  
  
  
    
  <div class="pagination">
    
      <span class="disabled">&laquo; Previous</span>
    
    | 1 |
    
      <a href="page/2/">Next &raquo;</a>
    
  </div>

  

    </article>
    <footer class="container-fluid ">
      <ul class="nav">
  <li class="nav-item copyright">
    <span class="nav-link">&copy; 2025 <a href="../work/">Martin HÃ¤cker</a></span>
  </li>
  
    
    <li class="nav-item imprint">
      <a class="nav-link" href="../meta/#imprint">
        Imprint
      </a></li>
  
    
    <li class="nav-item privacy-policy">
      <a class="nav-link" href="../meta/#privacy-policy">
        Privacy Policy
      </a></li>
  
    
    <li class="nav-item colophon">
      <a class="nav-link" href="../meta/#colophon">
        Colophon
      </a></li>
  
  <li class="ml-auto nav-item rss-feed">
    <a class="nav-link" href="../../blog/feed.xml">
      <img class="rss-icon" src=/static/rss.svg height=25 width=25>
      <span class="sr-only">RSS-Feed</span>
    </a>
  </li>
  <li class="nav-item license">
    <a class="nav-link" 
      rel="license" 
      target="_blank" 
      href="https://creativecommons.org/licenses/by-sa/4.0/deed"
    >
      <img 
        src="/static/cc-by-sa-88x31.png"
        alt="Creative Commons Attribution - Share Alike 4.0 International Lizense"
      >
    </a>
  </li>
</ul>
    </footer>
  </body>
</html>
