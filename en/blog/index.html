
<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="../../static/bootstrap-4.1.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="../../static/style.css">
    <link rel="stylesheet" href="../../static/pygments.css">
    <title>Blog</title>
    <link rel="alternate" type="application/atom+xml" title="RSS: Martin Häckers Blog Artikel" href="../../blog/feed.xml" />
  </head>
  <body>
    <header>
      <nav class="navbar navbar-expand-sm">
  <a href="../" class="navbar-brand ">🏠</a>
  <input type="checkbox" id="navbar-toggle-checkbox">
  <label for="navbar-toggle-checkbox" class="navbar-brand navbar-toggle d-sm-none float-right" aria-label="Navigation Umschalten">
    <span></span>
  </label>
  <ul class="navbar-nav collapse navbar-collapse">
    
      <li class="nav-item "><a href="../work/" class="nav-link">Professional software development</a></li>
    
      <li class="nav-item "><a href="../projects/" class="nav-link">Projects</a></li>
    
      <li class="nav-item "><a href="../publications/" class="nav-link">Publications and talks</a></li>
    
      <li class="nav-item active"><a href="./" class="nav-link">Blog<span class="sr-only">(ausgewählt)</span></a></li>
    
      <li class="nav-item "><a href="../categories/" class="nav-link">Categories</a></li>
    
    <li class="nav-item ml-auto">
      <a class=nav-link href="../../blog/">🇩🇪</a>
    </li>
    <li class="nav-item pull-right">
      <a class=nav-link href="./">🇬🇧</a>
    </li>
  </ul>
</nav>
<nav class="breadcrumb">
  

  

<a class="breadcrumb-item " href="../">🏠</a>


<a class="breadcrumb-item active" href="./">Blog</a>

</nav>
    </header>
    <article class="page blog  container-fluid">
      
  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/9/warum-man-backups-und-disaster-recovery-zusammen-denken-sollte/">
        Backup ohne verprobte Recovery ist wertlos – 5 Gründe
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-09-29">Monday, September 29, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/9/warum-man-backups-und-disaster-recovery-zusammen-denken-sollte/backup-ohne-recovery.png" alt="Backup und Recovery"></p>
<p>Auf der DevOpsCon 25 in Berlin habe ich viel aus dem Vortrag <a href="https://devopscon.io/devsecops/backup-disaster-recovery/">Backup and Disaster Recovery: Business as Usual or What Needs to Change Now? - DevOps Conference &amp; Camps</a> gezogen. Zum technischen Inhalt gehe ich noch mal Separat ein, aber zuerst wollte ich meine Schlüssel-Lernergebnisse auf einer sehr hohen Flughöhe mitbringen.</p>
<h2>1. Backups ohne Restore sind nur Datenfriedhöfe</h2>
<p>Ein Backup ist kein Wert an sich. Es ist nur die Basis für Geschäftskontinuität – erst der funktionierende Restore bringt das Unternehmen zurück ins Geschäft.</p>
<h2>2. Zeit entscheidet über Resilienz</h2>
<p>Recovery Time Objective (RTO) ist der kritische Faktor – nicht die schiere Menge oder Existenz von Kopien. Entscheidend ist: Wie lange darf welcher Teil des Geschäfts ausfallen, bis es ernsthafte Schäden nimmt?</p>
<h2>3. Kontinuierlicher Minimal-Restore trennt Dauer von Ausfallzeit</h2>
<p>Ein innovativer Ansatz ist, kontinuierlich eine schlanke, nicht skalierte Version der Systeme aus den Backups hochzufahren. Damit lässt sich jederzeit beweisen: Restore funktioniert. Und: Die Dauer des eigentlichen Restore-Vorgangs aus den Backups kann nahezu beliebig sein, ohne wesentlich das RTO zu gefährden.</p>
<h2>4. Vorhersagbare Skalierung statt unberechenbarer Wiederanlauf</h2>
<p>Im Notfall geht es nicht darum, <em>ob</em> das Backup läuft, sondern <em>wie schnell</em> man wieder auf ausreichende Kapazität kommt. Wer Skalierung auf Abruf plant, kennt die Antwort: „In X Minuten / Stunden ist die  Leistung verfügbar.“ Das macht den Unterschied zwischen Chaos und geplanter Resilienz.</p>
<h2>5. Kosteneffizienz und Compliance in einem</h2>
<p>Statt teurer Standby-Infrastruktur entsteht ein Modell, das laufend minimale Kosten verursacht, aber im Ernstfall sofort hochskaliert. Dazu kommt: Unternehmen erfüllen so auch regulatorische Anforderungen nach nachweisbarer Wiederanlauffähigkeit.</p>
<p><strong>Fazit:</strong>
Backups sind nur der Anfang. Erst wenn Restore und Disaster Recovery gemeinsam gedacht werden – mit kontinuierlichem Minimal-Restore und skalierbarer Infrastruktur – entsteht echte Business-Kontinuität.</p>

    </section>
    
      <footer>
        <a href="2025/9/warum-man-backups-und-disaster-recovery-zusammen-denken-sollte/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/9/textbearbeitung-mit-grep-tr-cut-awk-und-sed/">
        Textbearbeitung auf der Shell: grep, cut, awk, sed und tr
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-09-25">Thursday, September 25, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/9/textbearbeitung-mit-grep-tr-cut-awk-und-sed/tr-in-action.png" alt="`tr` in aktion"></p>
<p>Diese fünf kleinen Tools sind echte Arbeitspferde für jeden, der mit Text auf der Kommandozeile arbeitet. Sie haben viele Optionen – aber man braucht nicht alles zu kennen. Schon mit ein paar Grundbefehlen kann man 80 % der typischen Aufgaben lösen.</p>
<h3>1. <code>grep</code> – Zeilen finden</h3>
<p>grep filtert Textzeilen anhand von Mustern. Praktisch, wenn man in langen Outputs schnell das Relevante sehen will.</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Textzeilen ausgeben, die ein Wort enthalten</td>
<td><code>grep PATTERN</code></td>
<td>`cat protokoll.txt</td>
<td>grep "Fehler"`</td>
</tr>
<tr>
<td>Zeilen ausschließen</td>
<td><code>grep -v PATTERN</code></td>
<td><code>grep -v "^#" protokoll.txt</code></td>
</tr>
<tr>
<td>In einem ganzen Projektbaum nach</td>
<td><code>grep -r PATTERN DIR</code></td>
<td><code>grep -r "TODO" src/</code></td>
</tr>
</tbody>
</table>
<p><strong>Tipps</strong></p>
<ul>
<li><code>-i</code> ignoriert Groß/Kleinschreibung</li>
<li><code>-e</code> aktiviert Reguläre Ausdrücke (unter linux gibt es noch <code>-P</code> für Perl-kompatible Regex)</li>
</ul>
<p>Kombinationen über Pipes machen grep besonders stark:</p>
<div class="hll"><pre><span></span>grep<span class="w"> </span>-r<span class="w"> </span>-P<span class="w"> </span><span class="s2">&quot;def \w*\(&quot;</span><span class="w"> </span>.<span class="w"> </span>--after-context<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span><span class="s2">&quot;foo&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span><span class="s2">&quot;bar&quot;</span>
</pre></div>
<p>Für große Projekte lohnt sich ripgrep (rg), weil es schneller ist, <code>.gitignore</code> respektiert und reguläre Ausdrücke standardmäßig aktiviert.</p>
<h3>2. <code>cut</code> – Spalten und Zeichen</h3>
<p><code>cut</code> schneidet Spalten oder Zeichen aus Textzeilen heraus. Funktioniert am besten, wenn der Trenner ein einzelnes Zeichen ist.</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spalte 2 eine CSV <sup class="footnote-ref" id="fnref-csv"><a href="#fn-csv">1</a></sup></td>
<td><code>-d ',' -f 2</code></td>
<td><code>cut -d ',' -f 2 daten.csv</code></td>
</tr>
<tr>
<td>Zeichen 5‑10 einer Zeile</td>
<td><code>-c 5-10</code></td>
<td><code>cut -c 5-10 string.txt</code></td>
</tr>
<tr>
<td>Mehrere Felder</td>
<td><code>-f 1,3,5</code></td>
<td><code>cut -d ';' -f 1,3,5 daten.txt</code></td>
</tr>
</tbody>
</table>
<p>Bei Whitespace-getrennten Daten stößt cut an Grenzen – da ist <code>awk</code> besser.</p>
<h3>3. <code>awk</code> – Felder und Muster</h3>
<p><code>awk</code> versteht Texte als Felder, getrennt durch Whitespace oder ein angegebenes Zeichen. Wenn man möchte, kann man mit <code>awk</code> Text-Dateien fast wie Datenbanken abfragen, aber für den Anfang:</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Spalten ausgeben</td>
<td><code>{print $1, $3}</code></td>
<td><code>awk '{print $1, $3}' daten.txt</code></td>
</tr>
<tr>
<td>Letzte Spalte ausgeben</td>
<td><code>{print $NF}</code></td>
<td><code>awk '{print $NF}' daten.txt</code></td>
</tr>
<tr>
<td>Summe einer Spalte</td>
<td><code>{s+=$2} END {print s}</code></td>
<td><code>awk '{s+=$2} END {print s}' zahlen.txt</code></td>
</tr>
</tbody>
</table>
<p><strong>Nützliche Variablen</strong></p>
<ul>
<li><code>NF</code> = Anzahl Felder in der Zeile</li>
<li><code>NR</code> = aktuelle Zeilennummer</li>
</ul>
<h3>4. <code>sed</code> – Suchen und Ersetzen</h3>
<p><code>sed</code> ist ein Stream-Editor: ideal für Ersetzungen und einfache Transformationen.</p>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ersetzen</td>
<td><code>s/alt/neu/g</code></td>
<td><code>sed 's/Fehler/Warning/g' log.txt</code></td>
</tr>
</tbody>
</table>
<p>Vorsicht: Nie direkt in die gleiche Datei schreiben mit &gt; – sonst überschreibst du sie, bevor sie gelesen wurde. <strong>DAMIT HABE ICH SCHON DATEN VERLOREN</strong> Stattdessen:</p>
<div class="hll"><pre><span></span>sed<span class="w"> </span>-i<span class="w"> </span><span class="s1">&#39;s/alt/neu/g&#39;</span><span class="w"> </span>datei.txt<span class="w">   </span><span class="c1"># Direkt in der Datei ändern</span>
</pre></div>
<h3>5. <code>tr</code> – Zeichen übersetzen</h3>
<table>
<thead><tr>
<th>Aufgabe</th>
<th>Befehl</th>
<th>Beispiel</th>
</tr>
</thead>
<tbody>
<tr>
<td>Groß→Klein</td>
<td><code>tr [:upper:][:lower:]</code></td>
<td><code>tr '[:upper:]' '[:lower:]' &lt; input.txt</code></td>
</tr>
<tr>
<td>Leerzeichen löschen</td>
<td><code>tr -d ' '</code></td>
<td><code>tr -d ' ' &lt; file</code></td>
</tr>
<tr>
<td>ROT13 (Caesar‑Shift)</td>
<td><code>tr 'a-z' 'n-za-m'</code></td>
<td><code>tr 'a-z' 'n-za-m' &lt; text.txt</code></td>
</tr>
<tr>
<td>Mehrere Zeichen gleichzeitig</td>
<td><code>tr 'abc' 'ABC'</code></td>
<td><code>tr 'abc' 'ABC' &lt; input.txt</code></td>
</tr>
</tbody>
</table>
<p>Beispiel: <code>$PATH</code> lesbarer machen:</p>
<div class="hll"><pre><span></span>❯<span class="w"> </span><span class="nb">echo</span><span class="w"> </span><span class="nv">$PATH</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>tr<span class="w"> </span><span class="s1">&#39;:&#39;</span><span class="w"> </span><span class="s1">&#39;\n&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>nl
</pre></div>
<h2>Fazit</h2>
<ul>
<li><strong><code>grep</code></strong>: Zeilen nach Mustern filtern</li>
<li><strong><code>cut</code></strong>: Spalten oder Zeichen ausschneiden.</li>
<li><strong><code>awk</code></strong>: Felder flexibel verarbeiten und berechnen.</li>
<li><strong><code>sed</code></strong>: Ersetzen und transformieren</li>
<li><strong><code>tr</code></strong>: Zeichen umwandeln oder löschen</li>
</ul>
<p>👉 Zusammengeschaltet mit Pipes (<code>|</code>) werden diese Tools zu einem Schweizer Taschenmesser für Textbearbeitung – schnell, skriptbar und überall verfügbar.</p>
<div class="footnotes">
<hr>
<ol><li id="fn-csv"><p>CSV = Comma-Separated Values, kann natürlich auch maskierte Kommas in dem Wert enthalten, was dieser Befehl geflissentlich ignoriert oder falsch macht. Verwendet zum CSV-Parsen also bitte nicht diesen Shell-Befehl. Dieser Befehle sind dafür da, auf der Shell schnell mal in eine Datei hineinzuschauen. Wenn das Ergebnis gut genug ist, kann man es auch weiter verarbeiten.<a href="#fnref-csv" class="footnote">&#8617;</a></p></li>
</ol>
</div>

    </section>
    
      <footer>
        <a href="2025/9/textbearbeitung-mit-grep-tr-cut-awk-und-sed/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/8/arbeiten-mit-json-and-yaml-auf-der-shell/">
        Arbeiten mit JSON &amp; YAML auf der Shell
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-08-25">Monday, August 25, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/8/arbeiten-mit-json-and-yaml-auf-der-shell/yless.png" alt="yaml ganz angenem auf der Shell"></p>
<p>Arbeiten mit strukturierten Datenformaten auf der Shell kann anstrengend sein – <strong>wenn man noch nicht die richtigen Tools dafür hat</strong>.
Ob JSON aus einer API, YAML aus Kubernetes-Manifests oder riesige Logfiles – ohne passende Helferlein endet man schnell bei unübersichtlichem <code>grep</code>, <code>less</code> und Copy&amp;Paste.</p>
<p>Zum Glück gibt es eine Reihe von Werkzeugen, die genau dafür gemacht sind:</p>
<ul>
<li><strong>jq</strong> – JSON lesen, filtern und transformieren – <a href="https://jqlang.org">https://jqlang.org</a></li>
<li><strong>jo</strong> – JSON in der Shell erzeugen – <a href="https://github.com/jpmens/jo">https://github.com/jpmens/jo</a></li>
<li><strong>yq</strong> – YAML lesen, bearbeiten und konvertieren – <a href="https://mikefarah.gitbook.io/yq/">https://mikefarah.gitbook.io/yq/</a></li>
<li><strong>jless / yless</strong> – interaktiv in JSON/YAML navigieren – <a href="https://jless.io">https://jless.io</a></li>
</ul>
<p>In diesem Beitrag stelle ich euch diese Tools vor – mit Beispielen, die ihr direkt in eurer eigenen Shell ausprobieren könnt.</p>
<hr>
<h2>jq – der Klassiker für JSON</h2>
<p>Das vermutlich bekannteste und am weitesten verbreitete Tool für JSON ist <a href="https://jqlang.org"><strong><code>jq</code></strong></a>.
Es ist so etwas wie der <em>Schweizer Taschenmesser</em> für JSON:</p>
<ul>
<li>formatiert unlesbare Minified-JSON-Dateien,</li>
<li>extrahiert gezielt Werte,</li>
<li>filtert und transformiert Daten,</li>
<li>eignet sich für einmalige Ad-hoc-Analysen genauso wie für Skripte.</li>
</ul>
<p>Ein einfaches Beispiel: JSON schön formatieren:</p>
<pre><code>$ cat data.json
{"user":{"id":42,"name":"Alice"},"active":true}
$ cat data.json | jq # oder `jq &lt; data.json`
</code></pre>
<div class="hll"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">42</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Alice&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;active&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="p">}</span>
</pre></div>
<p>So schnell wird aus einem unübersichtlichen Einzeiler eine lesbare Struktur.</p>
<p>Mann kann es aber auch super in scripten verwenden um Daten aus json zu extrahieren:</p>
<div class="hll"><pre><span></span>get_current_gitlab_token<span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">    </span>kubectl<span class="w"> </span>get<span class="w"> </span>secret<span class="w"> </span><span class="nv">$SECRETNAME</span><span class="w"> </span>-n<span class="w"> </span><span class="nv">$INITIALNAMESPACE</span><span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="p">|</span>
<span class="w">        </span>jq<span class="w"> </span>-r<span class="w"> </span><span class="s1">&#39;.data[&quot;.dockerconfigjson&quot;]&#39;</span><span class="w"> </span><span class="m">2</span>&gt;/dev/null<span class="w"> </span><span class="p">|</span>
<span class="w">        </span>base64<span class="w"> </span>--decode<span class="w"> </span><span class="p">|</span>
<span class="w">        </span>jq<span class="w"> </span>-r<span class="w"> </span><span class="s1">&#39;.auths[&quot;registry.gitlab.com&quot;].password&#39;</span><span class="w"> </span><span class="m">2</span>&gt;/dev/null
<span class="o">}</span>
</pre></div>
<p>Oder um in einem JSON-File Daten einzutragen:</p>
<div class="hll"><pre><span></span>kubectl<span class="w"> </span>get<span class="w"> </span>secrets<span class="w"> </span>shipa-certificates<span class="w"> </span>-o<span class="w"> </span>json<span class="w"> </span><span class="se">\</span>
<span class="w">        </span><span class="p">|</span><span class="w"> </span>jq<span class="w"> </span><span class="s2">&quot;.data[\&quot;ca.pem\&quot;] |= \&quot;</span><span class="nv">$CA_CERT</span><span class="s2">\&quot;&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span><span class="p">|</span><span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>-
</pre></div>
<p><code>jq</code> kann noch viel mehr. Wer das Werkzeug noch nicht kennt sollte unbedingt ein paar Minuten investieren um <a href="https://jqlang.org/tutorial/">das Tutorial</a> querzulesen, und dann bei der nächsten Einsatzmöglichkeit gezielt nach der Syntax schauen. Pro tip: KI's können diese Syntax prima, und <code>jless</code> (kommt gleich) kann diese auch generieren.</p>
<hr>
<h2>jo – JSON in der Shell erzeugen</h2>
<p>Während <code>jq</code> ideal zum Lesen und Transformieren ist, eignet sich <strong><code>jo</code></strong> perfekt, um JSON direkt in der Shell zu erstellen. Damit lassen sich Testdaten oder API-Payloads schnell zusammenbauen.</p>
<p>Ein einfaches Beispiel:</p>
<div class="hll"><pre><span></span>jo<span class="w"> </span><span class="nv">name</span><span class="o">=</span>Alice<span class="w"> </span><span class="nv">age</span><span class="o">=</span><span class="m">30</span><span class="w"> </span><span class="nv">active</span><span class="o">=</span><span class="nb">true</span>
</pre></div>
<p>Ausgabe:</p>
<div class="hll"><pre><span></span><span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;Alice&quot;</span><span class="p">,</span><span class="nt">&quot;age&quot;</span><span class="p">:</span><span class="mi">30</span><span class="p">,</span><span class="nt">&quot;active&quot;</span><span class="p">:</span><span class="kc">true</span><span class="p">}</span>
</pre></div>
<p>Auch Arrays sind möglich:</p>
<div class="hll"><pre><span></span>jo<span class="w"> </span>-a<span class="w"> </span>red<span class="w"> </span>green<span class="w"> </span>blue
</pre></div>
<p>➜ <code>["red","green","blue"]</code></p>
<p>Verschachtelte Objekte:</p>
<div class="hll"><pre><span></span>jo<span class="w"> </span><span class="nv">user</span><span class="o">=</span><span class="k">$(</span>jo<span class="w"> </span><span class="nv">name</span><span class="o">=</span>Alice<span class="w"> </span><span class="nv">id</span><span class="o">=</span><span class="m">42</span><span class="k">)</span><span class="w"> </span><span class="nv">project</span><span class="o">=</span>Demo
</pre></div>
<p>➜ <code>{"user":{"name":"Alice","id":42},"project":"Demo"}</code></p>
<p>Das eignet sich sehr gut für schnelle <code>curl</code>-Requests, aber insbesondere auch für shell scripte in denen inline json sonst sehr schnell sehr unübersichtlich wird:</p>
<div class="hll"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-d<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>jo<span class="w"> </span><span class="nv">username</span><span class="o">=</span>dev<span class="w"> </span><span class="nv">password</span><span class="o">=</span>secret<span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>https://example.com/api/login
</pre></div>
<hr>
<h2>yq – YAML lesen und bearbeiten</h2>
<p>YAML verwenden wir überall, am meisten habe ich in Kubernetes damit zu tun. <a href="https://mikefarah.gitbook.io/yq/"><strong><code>yq</code></strong></a> ist das Werkzeug der Wahl, um YAML-Dateien zu lesen, zu durchsuchen und zu editieren. Die Syntax ist sehr nahe an <code>jq</code>, das Werkzeug kann neben YAML aber auch JSON, TOML und XML verarbeiten, und zwischen diesesn Konvertieren. Im wesentlichen kann es das gleiche wie <code>jq</code>, eben auch für YAML.</p>
<hr>
<h2>jless &amp; yless – interaktiv stöbern</h2>
<p>Wenn Dateien zu groß oder zu komplex werden, helfen <a href="https://jless.io"><strong><code>jless</code></strong></a> und <strong><code>yless</code></strong> (ein <code>alias yless=jless --yaml</code>. Sie bieten eine interaktive Ansicht für JSON und YAML – mit:</p>
<ul>
<li>Syntax-Highlighting,</li>
<li>Falten und Aufklappen von Strukturen,</li>
<li>komfortabler Navigation und Suche.</li>
</ul>
<p>Beispiel:</p>
<div class="hll"><pre><span></span>kubectl<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-oyaml<span class="w"> </span><span class="p">|</span><span class="w"> </span>yless
</pre></div>
<p>Das schöne: Man kann hier auf der Shell wunderbar uninteressante textblöcke einklappen um schnell die wichtigen Informationen zu fokussieren, und dann über Tastaturkommandos werte, oder jq/yq filter auf das aktuell ausgewählte Element kopieren, um das z.B. dann auf alle Pods in einem Namespace anzuwenden.</p>
<hr>
<h2>Fazit</h2>
<p>Mit diesen Tools – <code>jq</code>, <code>jo</code>, <code>yq</code>, <code>jless</code> und <code>yless</code> – wird das Arbeiten mit JSON und YAML auf der Shell <em>deutlich</em> angenehmer. Sehr gut investierte Zeit diese Werkzeuge (eines nach dem Anderen) zu lernen.</p>

    </section>
    
      <footer>
        <a href="2025/8/arbeiten-mit-json-and-yaml-auf-der-shell/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/8/mit-llm-rag-einfach-mal-ausprobieren-direkt-von-der-shell/">
        Mit llm RAG einfach mal ausprobieren – direkt von der Shell
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-08-07">Thursday, August 7, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/8/mit-llm-rag-einfach-mal-ausprobieren-direkt-von-der-shell/workflow.png" alt="Ablaufdiagramm">
Einer der coolsten Aha-Momente der letzten Tage bei mir war, wie einfach und niederschweflig das Arbeiten mit Retrieval-Augmented Generation (RAG) von der Shell inzwischen sein kann – ganz ohne spezielle Infrastruktur, Vektor-Datenbank oder Server-Backend. Das Python-Tool <a href="https://pypi.org/project/llm/"><code>llm</code></a> macht  das möglich: RAG direkt aus der Kommandozeile, mit SQLite als Backend und einfachen Kommandos, die sich hervorragend in Shell-Workflows integrieren lassen.</p>
<h2>Ein Power Tool für Sprachmodelle in der Shell</h2>
<p><a href="https://llm.datasette.io/en/stable/"><code>llm</code> kann natürlich noch viel mehr und ist ein Power Tool, das den Einsatz von KI direkt im Terminal erlaubt</a>. Es erlaubt mit beliebigen API-Providern oder lokalen Modellen zu sprechen und integriert diese damit nahtlos in eigene Skripte. Use Cases: Daten hinein pipen und mit dem LLM bearbeiten. Ob zusammenfassen, erklären, übersetzen, mit einem aufwendigen Prompt aus einer Datei beackern… Da geht so viel. Egal was Ihr aus diesem Artikel mitnehmt, zumindest sollte es sein das Ihr <code>llm</code> in euren Workflow aufnehmt und installiert.</p>
<h2>Der RAG-Workflow von der Shell aus</h2>
<p>Ein kompletter RAG-Workflow funktioniert mit <code>llm</code> in wenigen Schritten. <a href="https://building-with-llms-pycon-2025.readthedocs.io/en/latest/semantic-search-and-rag.html">Diese Demo hier hab ich von Simon Willison geklaut, dem Autor von <code>llm</code></a>. <a href="https://github.com/python/peps">Hier wird semantische Suche in den Python Enhancement Proposals demonstriert</a>. Dieses Tutorial verwendet einen lokalen LLM-Server, man kann das aber natürlich auch mit GitHub Copilot oder ähnlichen Modellen machen. Herauszufinden wie die dort heißen und zu verbinden sind bleibt ein Exercise für den Leser.</p>
<h3>1. Dateien vorbereiten</h3>
<p>Wir erstellen gekürzte Versionen von Textdateien:</p>
<div class="hll"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>peps-truncated
<span class="k">for</span><span class="w"> </span>f<span class="w"> </span><span class="k">in</span><span class="w"> </span>peps/*.rst<span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">  </span>head<span class="w"> </span>-c<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$f</span><span class="s2">&quot;</span><span class="w"> </span>&gt;<span class="w"> </span><span class="s2">&quot;peps-truncated/</span><span class="k">$(</span>basename<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$f</span><span class="s2">&quot;</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="k">done</span>
</pre></div>
<p>Das ist natürlich streng genommen falsch, weil wir ganz viel Daten wegschmeißen. Einiges spricht aber trotzdem dafür:</p>
<ol>
<li>Gerade lokale Modelle haben gerne nicht so große Kontext-Fenster und da muss das Dokument reinpassen.</li>
<li>Meistens steht am Anfang eines Dokuments worum es geht. Für unsere Zwecke also eine gute Näherung.</li>
</ol>
<p>Um das später in ein Produkt umzuwandeln müssten wir uns noch weitere Strategien anschauen, z.B. mit einem Sliding Window über die Dokumente zu gehen und für jeden Abschnitt ein Embedding zu erzeugen. Grundsätzlich ist es aber eine gute Idee verschiedene Indexe zu erzeugen die unterschiedliche Zwecke erfüllen.</p>
<h3>2. Vektor-Index erstellen</h3>
<div class="hll"><pre><span></span>llm<span class="w"> </span>embed-multi<span class="w"> </span>peps<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-m<span class="w"> </span>mxbai-embed-large<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--files<span class="w"> </span>peps-truncated<span class="w"> </span><span class="s1">&#39;pep-3*.rst&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-d<span class="w"> </span>peps.db<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--store
</pre></div>
<p>Das erzeugt eine SQLite-Datenbank mit eingebetteten Vektoren. Wichtig: Die Datenbank speichert auch, mit welchem Modell die Einbettung erfolgte – bei weiteren Operationen auf der gleichen Collection <code>peps</code> ignoriert <code>llm</code> den Modell-Parameter ohne Fehlermeldung!</p>
<p>Seiten-Notiz: Embeddings, was ist das? Ein Embedding ist eine Umwandlung von einem Text in eine Zahlenreihe (Mathematisch: Einen Vektor). Jeder dieser Vektoren beschreibt eine Koordinate in einem Hoch-Dimensionalen Raum, mit der Eigenschaft, das Koordinaten die sich Nahe sind von einem Text kommen der semantisch Ähnlich ist. Darin kann man sogar Rechnen, ein etwas überstrapaziertes Beispiel wäre z.B. der Vektor für König + Weiblich = Königin. <a href="https://simonwillison.net/2023/Oct/23/embeddings/">Mehr gibts hier</a></p>
<h3>3. Abfragen stellen</h3>
<div class="hll"><pre><span></span>llm<span class="w"> </span>similar<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;What do string templates look like?&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span>peps.db<span class="w"> </span>-n<span class="w"> </span><span class="m">2</span><span class="w"> </span>peps<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="p">|</span><span class="w"> </span>llm<span class="w"> </span>-s<span class="w"> </span><span class="s2">&quot;Answer the question: What do string templates look like?&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-m<span class="w"> </span>devstral<span class="w"> </span>-o<span class="w"> </span>num_ctx<span class="w"> </span>256_00
</pre></div>
<p>Hier wird erst ähnliche Inhalte zur Frage gesucht. Wichtige Details: Das Kontext-Fenster des Sprachmodells das antwortet muss groß genug sein, das es alle Antworten in seinen Kontext aufnehmen kann. Ansonsten wird gerne der Anfang abgeschnitten - und da steht natürlich der Treffer mit dem besten Score.</p>
<h3>4. Automatisieren</h3>
<p>Wir können sogar direkt ein Skript generieren lassen:</p>
<div class="hll"><pre><span></span>llm<span class="w"> </span><span class="s1">&#39;</span>
<span class="s1">Build me a bash script like this:</span>
<span class="s1">./pep-qa.sh &quot;What do string templates look like?&quot;</span>
<span class="s1">It should first run:</span>
<span class="s1">llm similar -c $question -d peps.db peps</span>
<span class="s1">Then it should pipe the output from that to:</span>
<span class="s1">llm -s &quot;Answer the question: $question&quot; -m gpt-4.1-mini</span>
<span class="s1">That last command should run so the output is visible as it runs.</span>
<span class="s1">&#39;</span><span class="w"> </span>-x<span class="w"> </span>&gt;<span class="w"> </span>pep-qa.sh
</pre></div>
<h2>Fazit</h2>
<p>Was früher nach viel Setup aussah (Vektor-Datenbank, Backend-API, RAG-Pipeline), ist heute in wenigen Shell-Befehlen machbar. SQLite funktioniert dabei erstaunlich gut – <code>llm</code> führt einfach einen Full-Table-Scan durch und berechnet die Vektor-Abstände direkt. Das ist nicht hyper-skalierbar, aber bis 10.000 bis 100.000 Einträge durchaus brauchbar.</p>
<p>Und das Beste: <code>llm</code> lässt sich überall in bestehende Shell-Skripte und Workflows einbauen – sogar mit piped Input. Wer also mal eben eine intelligente Suche oder ein Sprachmodell in seinen CLI-Workflow integrieren will, findet hier ein extrem mächtiges Toolset.</p>
<p>Ich kann nur empfehlen ein Shell-Werkzeug wie <code>llm</code> zu lernen.</p>

    </section>
    
      <footer>
        <a href="2025/8/mit-llm-rag-einfach-mal-ausprobieren-direkt-von-der-shell/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/7/devopscon-keynote-security-ist-jetzt-teil-von-devops/">
        DevOpsCon Keynote – Security ist jetzt Teil von DevOps?
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-07-30">Wednesday, July 30, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/7/devopscon-keynote-security-ist-jetzt-teil-von-devops/secure-chips.png" alt="Metapher auf Teams die jeweils Sicherheits-Interessierte enthalten, die einfach von Spezialisten Unterstützung erhalten können"></p>
<p>Ich konnte auf der DevOpsCon der Keynote "From Static to Strategic: Reimagining Application Security for a DevOps World" von John D. Wood nicht entgehen. Um ehrlich zu sein: Die Keynote hat mich nicht begeistert. Am ehesten noch fand ich interessant das er Zahlen hatte, das die meisten Sicherheitslücken (auch nach Bekanntwerden) noch über ein Dreiviertel-Jahr offen sind. Aua. Ein Satz am Ende ist bei mir hängengeblieben:</p>
<blockquote><p>"DevOps bekommt jetzt auch Security."</p>
</blockquote>
<p>Was simpel klingt, ist in der Realität alles andere als einfach – und betrifft uns ganz konkret. In einer Zeit, in der wir als Unternehmen KRITIS-relevant geworden sind, ist es für viele Risiken nicht mehr möglich sie einfach zu übernehmen (AKA aussitzen). Wir müssen sie aktiv mitigieren – und das gilt besonders auch für Security-Risiken.</p>
<h3>Security: Aus DevOps wird "DevSecOps"?</h3>
<p>Dev ist schon schwer. Ops noch schwieriger. Und jetzt kommt Security obendrauf. Nicht jedes Team kann oder will alle drei Disziplinen gleich gut abdecken. Und dennoch ist klar: Es kommt mehr Arbeit auf uns zu.</p>
<p>Wir werden bei bestimmten Anwendungen in Zukunft viel stärker darauf achten müssen:</p>
<ul>
<li>Dass Betriebssysteme (in Docker-Containern) aktuell sind,</li>
<li>Dass Projektabhängigkeiten regelmäßig gepflegt werden,</li>
<li>Dass wir verstehen, <em>welche Sicherheitslücken für <strong>uns</strong> relevant</em> sind – nicht nur, weil ein Scanner sie anmeckert, sondern weil unsere eigene Risikoabwägung sie als kritisch einstuft.</li>
</ul>
<h3>Wunsch-Szenario: Expertise teilen, nicht duplizieren</h3>
<p>Mein Wunsch wäre, dass nicht jedes Team die komplette Security-Expertise selbst aufbauen muss. Stattdessen sollten sich diejenigen, die sich besonders für das Thema interessieren, tiefer einarbeiten können – und jederzeit unkompliziert Zugang zu  Spezialist\:innen haben. Idealerweise entsteht daraus eine Art Mentoring-Beziehung.</p>
<p>Das Ziel: Schnell und unbürokratisch Expertise bekommen, wenn man merkt, dass man sie braucht. Entwickler\:innen sollen lernen, Security-relevante Situationen zu erkennen und wissen, wo sie gezielt und niederschwellig Unterstützung finden.</p>
<h3>Compliance-Checkbox oder echte Verteidigung?</h3>
<p>Ein starkes Bild aus dem Vortrag war die Kritik an klassischen Security-Prozessen: Wöchentliche Scans, lange Backlogs mit offenen CVEs, endlos False Positives, wenig konkreter Nutzen. All das erzeugt ungeplante Arbeit, und widerspricht damit dem DevOps-Grundsatz "No unplanned work" – und hilft im Ernstfall wenig. Letztlich müssen wir ja die Daten unserer Versicherten Schützen, dass der Bug den ein Angreifer bei uns Ausgenützt hat schon lange bekannt war, hilft uns nicht weiter.</p>
<h3>Fazit</h3>
<p>Ich nehme aus dem Talk vor allem eines mit: Security können wir in Zukunft nicht länger als "Problem von jemand anderem" verstehen. Sie ist jetzt (oder wird es bald) integraler Teil von DevOps – ob uns das passt oder nicht.</p>
<p>Und wir müssen Wege finden, wie wir das <em>gemeinsam</em> schultern können – weil wir eben nicht jeden Entwickler zum Security-Experten machen können.</p>

    </section>
    
      <footer>
        <a href="2025/7/devopscon-keynote-security-ist-jetzt-teil-von-devops/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/7/die-bittere-realitaet-container-sicherheit-ist-kaputt/">
        Die bittere Realität: Container-Sicherheit ist Kaputt
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-07-16">Wednesday, July 16, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/7/die-bittere-realitaet-container-sicherheit-ist-kaputt/chainguard-cve-history.png" alt="Container Security">
Vor einigen Wochen war ich auf der DevOpsCon in Berlin. Einer der spannenderen  Vorträge war für mich: <strong>"Supply Chain Security and the real world: Lessons from Incidents"</strong>. Offiziell ging es um Sicherheit in Container-Umgebungen. Inoffiziell war es eine Abrechnung mit dem Chaos, das wir im Alltag mit Docker-Containern erleben.</p>
<p>Wir alle lieben Docker Hub: Schnell ein Image ziehen, starten, fertig. Aber was dabei oft vergessen wird: Selbst die als "offiziell" markierten Container bieten keinerlei Garantien. Weder über die Aktualität noch über Sicherheit. Fast alle dieser Container werden monatelang nicht aktualisiert, obwohl es CVEs für enthaltene Komponenten gibt.</p>
<p>Wenn man das ernst nimmt, müsste man:</p>
<ul>
<li>Alle Container regelmäßig selbst neu bauen und dabei Updates der darin enthaltenen Distributionen installieren</li>
<li>Bei jeder Abhängigkeit überwachen, ob es CVEs oder Updates gibt</li>
<li>Die Upstream-Projekte verstehen, ihre Update-Kanäle abonnieren</li>
<li>Alle Dockerfiles durchdringen (insbesondere bizarr manuell installierter Binaries)</li>
</ul>
<p>Kurz: Wer Container sicher betreiben will, muss eigentlich selbst zur Distribution werden.</p>
<h3>Die Lösung: "Start Left" statt "Shift Left"</h3>
<p>Die Firma <strong>Chainguard</strong> hat in dem Vortrag ihre Alternative vorgestellt: Ein Repository von sicherheitsoptimierten, rootlosen Containern, die alle:</p>
<ul>
<li><strong>ohne bekannte CVEs</strong> ausgeliefert werden</li>
<li>auf einem selbstgebauten, deterministischen OS basieren ("Wolfi", im wesentlichen Alpine mit GLibC statt Musl)</li>
<li>reproduzierbar gebaut werden (jede\:r kann sie nachbauen, wenn auch nicht Bit für Bit)</li>
<li>mit Software-Bill-of-Materials (SBOM) ausgeliefert werden</li>
<li>Auch im Container als normale Nutzer ausgeführt werden anstatt als `root`</li>
<li>und bei neuen Upstream-Vulnerabilities innerhalb von 7 Tagen gepatcht werden</li>
</ul>
<p>Die Container sind FIPS-kompatibel, in zwei Varianten (Production vs. Dev - mit mehr Tools) verfügbar und mit bekannten Tools wie <code>trivy</code> problemlos scannbar. Offen Statistiken zeigen beeindruckend wie <em>viel weniger CVEs</em> sieh in Ihren Containern haben. Nämlich in der Regel gar keine.</p>
<h3>Warum das für viele ein Game-Changer sein könnte</h3>
<p>Wie in vielen Unternehmen, ist auch bei uns die Nutzung von Docker-Containern ein "Free for All": Jeder zieht, was er braucht, hauptsache es läuft. Sicherheitsrichtlinien? Nicht vorhanden. Updates? Machen wir Manuell alle Jubeljahre. Genau hier setzen die Container von Chainguard (oder auch Dockers eigene "Hardened Images") an:</p>
<p>Man könnte sagen:</p>
<blockquote><p>Was sonst niemand zuverlässig macht, macht ChainGuard automatisch.</p>
</blockquote>
<p>Und das Beste: Die Basis-Container sind sogar kostenlos (und damit z.B. auch für Open Source Projekte) verwendbar. Damit kann man ohne großen Aufwand den Produktivbetrieb auf eine wesentlich sicherere Basis stellen.</p>
<p>Gerade wenn man – wie bei KRITIS-Vorgegeben – innerhalb eines festen Zeitrahmens Sicherheitsupdates einspielen muss, ist eine verlässliche Update-Garantie Gold wert.</p>
<h3>Mein Fazit</h3>
<p>Container sind kein Selbstzweck – und sie haben einen großen Nachteil gegenüber Veränderbarer Infrastruktur: Man verliert die automatisch installierten Updates der Linux Distributionen. Wer diesen Aufwand nicht selbst stemmen will, braucht Alternativen. Die gehärteten Container von ChainGuard oder Docker sind ein vielversprechender Weg, um  mit minimalem Aufwand viel weniger CVEs und fehlender Updates, sowie weit mehr Transparenz gewinnen kann.</p>
<p>Probiert es doch mal aus. Ich würde mich sehr über Feedback freuen wo die Grenzen und Probleme dieses Ansatzes liegen. Offensichtlich ist schon mal, dass dort nicht so viele Container gibt.</p>
<p>Grundsätzlich aber immer: Bitte Entscheidet euch bewusst für Images, die gepflegt werden. Und nicht für das erste, das die Suche auf Docker Hub zurück gibt.</p>

    </section>
    
      <footer>
        <a href="2025/7/die-bittere-realitaet-container-sicherheit-ist-kaputt/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/6/nuetzliche-shell-kommandos-sort-uniq/">
        Nützliche Shell-Kommandos: sort, uniq
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-06-25">Wednesday, June 25, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/6/nuetzliche-shell-kommandos-sort-uniq/set-operations.png" alt="Set Operations">
Weil ich es heute wiederholt nachschlagen musste, hier noch eine Erinnerung an mich selbst, wie einfach es ist auf der Shell set Operationen durchzuführen.</p>
<p>In unserem Beispiel: ~10k Datenbank-IDs hier, ~15k Datenbank-IDs da, und die Frage welche davon nur in der einen Liste enthalten sind. Das ist dann einfach zu beantworten, wenn man die auf eine ID pro Zeile ausgibt, und dann einfach mit <code>set_difference</code> bearbeitet.</p>
<div class="hll"><pre><span></span>set_union<span class="w"> </span><span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq
<span class="o">}</span>

set_intersection<span class="w"> </span><span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>--repeated
<span class="o">}</span>

set_difference<span class="w"> </span><span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>--unique
<span class="o">}</span>

set_symmetric_difference<span class="o">()</span><span class="w"> </span><span class="o">{</span>
<span class="w">   </span>sort<span class="w"> </span><span class="nv">$1</span><span class="w"> </span><span class="nv">$2</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span>--unique
<span class="o">}</span>
</pre></div>
<p><a href="https://stackoverflow.com/a/13038235/4572750">Quelle</a></p>

    </section>
    
      <footer>
        <a href="2025/6/nuetzliche-shell-kommandos-sort-uniq/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/6/devopscon-stolperfallen-beim-aufbau-interner-developer-platforms-idp/">
        DevOpsCon: Stolperfallen beim Aufbau interner Developer Platforms (IDP)
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-06-19">Thursday, June 19, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p>Heute gibts den Start meines Berichts von der DevOpsCon 25. So viel allgemeines vorweg: War schön.  Druckbetankung wie es sich gehört.</p>
<p>Los ging es mit einer Keynote über interne Entwickler-Plattformen und was dabei gerne schief geht.</p>
<h2>1 | Reality-Check: 90 % der Devs nutzen schon eine IDP – wir auch</h2>
<ul>
<li>Laut Jessica arbeiten rund 90 % aller Entwickler:innen mittlerweile mit einer internen Plattform – oft, ohne es zu merken.</li>
<li>Wir auch? Was ist unsere Plattform?</li>
</ul>
<h2>2 | Das theoretische Fundament</h2>
<p>Jessica empfahl <em>vier Bücher</em>, die jede:r Platform‑Builder kennen sollte. (Lustigerweise gab Sie zu, das Sie selbst noch nicht alle davon gelesen komplett gelesen hat.)</p>
<table>
<thead><tr>
<th>Buch</th>
<th>Kernaussage für IDP</th>
<th>Mein Take‑away</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="https://www.amazon.com/Transformed-Becoming-Product-Driven-Company-Silicon/dp/1119697336">Transformed</a></strong></td>
<td>Von Silos zu <strong>empowereden Produkt‑Teams</strong></td>
<td>Auch Plattform‑Teams brauchen Produktdenken und Produkt-Manager.</td>
</tr>
<tr>
<td><strong><a href="https://www.amazon.com/Team-Topologies-Organizing-Business-Technology/dp/1942788819">Team Topologies</a></strong></td>
<td><strong>Team‑Typen &amp; Schnittstellen</strong> (u. a. Platform &amp; Enabling Teams)</td>
<td>Klingt sehr ähnlich zu dem wie wir organisiert sind. Unterschiede: Komplizierte Subsysteme brauchen eigene Teams. Enabling‑Teams sind hier fast immer <strong>temporär</strong>.</td>
</tr>
<tr>
<td><strong><a href="https://www.amazon.de/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">Accelerate</a></strong></td>
<td>Deploy‑Freq., Lead‑Time, Failure‑Rate, MTTR</td>
<td><a href="https://dora.dev/guides/dora-metrics-four-keys/">DORA‑Scores</a> = Proxy für Platform-Team‑Erfolg. Nugget: Im Raum war niemand der alle 4 Metriken einsetzt, oder jemanden kennt der das tut…</td>
</tr>
<tr>
<td><strong><a href="https://www.amazon.de/Platform-Engineering-Technical-Product-Leaders/dp/1098153642">Platform Engineering</a></strong></td>
<td><strong>Plattform ersetzt Glue‑Code</strong> &amp; schafft Self‑Service</td>
<td>Eine IDP ist <strong>Software</strong>, kein Ops‑Team.</td>
</tr>
</tbody>
</table>
<h2>3 | Typische Fallstricke</h2>
<ol>
<li><strong>Menschen im Plattform-Team bringen ihre Erfahrungen mit</strong><ul>
<li>„It’s faster if I just do it.“ Sorgt gerne dafür das das Ergebnis auch nur Sie benutzen können.</li>
<li>Damit erzeugt man ein neues Ops-Silo. Dringend zu vermeiden. Das Ziel ist, das andere Teams sich selbst helfen können.</li>
</ul>
</li>
<li><strong>Rudis Resterampe</strong> (Scope Creep)<ul>
<li>Plattform‑Team sammelt alles, was sonst niemand machen will.</li>
<li>Konsequenz: Keine Zeit mehr für strategische Funktionen.</li>
<li>Braucht eine klare Vision, und insbesondere By-In von Leadership. Dann Iterationen und viel Kommunikation.</li>
</ul>
</li>
<li><strong>Alles sofort lösen wollen (Rudis Resterampe 2.0)</strong><ul>
<li>Minimalismus ist King 👑. Nicht jedes Problem muss gleich gelöst werden.</li>
<li>Priorisiere <strong>Onboarding, Self‑Service &amp; Empowerment</strong>.</li>
</ul>
</li>
<li><strong>Das falsche Problem Lösen</strong><ol>
<li>Es ist sehr einfach das falsche Problem zu lösen. Schließlich sind wir alle Entwickler und wissen was wir brauchen.</li>
<li>Aber jedes Team ist anders und hat andere Aufgaben. Daher ist es unglaublich wichtig mit den Menschen intensiv zu sprechen die man beglücken will.</li>
<li>Plattform-Engineering braucht genauso Produkt-Management und einen Produkt-Manager wie andere Themen. Wenn das Budget dafür nicht vorhanden ist, muss man diese Aufgaben trotzdem erfüllen.</li>
</ol>
</li>
<li><strong>Plattform‑Migrationen unterschätzen</strong><ul>
<li>Jede Migration ist Schmerzhaft und <strong>kostet Vertrauen</strong> (Vertrauen ist wie eine Währung. Wenn man es ausgegeben hat, ists wech).</li>
<li>Daher so wenig Migrationen wie möglich, und diese gut vorbereiten, auch wenn es viel Aufwand erzeugt.</li>
<li>Ziel: <strong>Automatisierte, Low‑Impact‑Migrationspfade</strong>.</li>
</ul>
</li>
</ol>
<h2>4 | Fragen an den Leser</h2>
<ol>
<li><strong>Was ist deine aktuelle Plattform?</strong></li>
<li><strong>Wo klemmt es eigentlich derzeit?</strong></li>
<li><strong>Macht es Sinn die DORA‑Baselines zu</strong> messen?</li>
</ol>
<h2>5 | Fazit</h2>
<p>Ein internes Developer‑Platform‑Team ist <strong>kein Sonder‑Ops‑Team</strong>, sondern ein <strong>Produkt‑Team</strong> mit klarer Vision, fokussiertem Scope und messbarem Impact.
Je einfacher, desto besser – und Vertrauen ist kostbar.</p>
<blockquote><p><em>„Minimalismus ist King – löse die wichtigsten 20 % zuerst, die den Teams 80 % des Schmerzes nehmen.“</em> – Jessica Anderson</p>
</blockquote>

    </section>
    
      <footer>
        <a href="2025/6/devopscon-stolperfallen-beim-aufbau-interner-developer-platforms-idp/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/5/die-freuden-einer-gut-eingerichteten-shell-fzf/">
        Die Freuden einer gut eingerichteten Shell: fzf
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-05-07">Wednesday, May 7, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <p><img src="2025/5/die-freuden-einer-gut-eingerichteten-shell-fzf/fzf.png" alt="fzf"></p>
<p>Nachdem es bisher in <a href="../../categories/code/">der Serie</a> um die <a href="../../blog/2024/11/grundlegende-funktionen-und-einstellungen-des-terminals/">grundlegende Einrichtung der Shell</a>, <a href="../../blog/2025/2/die-freuden-einer-gut-eingerichteten-shell-prompt/">einen guten Prompt</a> und <a href="../../blog/2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/">funktionierende autoomatische Vervollständigung</a> ging, geht es jetzt eine Weile um Werkzeuge um mit der Shell effizient zu navigieren und Dateien und Inhalte zu finden.</p>
<h2>Einleitung</h2>
<p>Hier geht es mir darum das die Arbeit auf der Shell (auf dem eigenen Rechner vor allem) nur dann schnell und Effizient ist, wenn man schnel und einfach in die Ordner kommt in denen man arbeiten möchte, und die Dateien findet in denen etwas interessantes steht das man entweder lesen oder verändern möchte.</p>
<p>Und natürlich ist das Skillset auch auf beliebige Server transferierbar, weil man alle diese Werkzeuge (oder deren etwas primitivere Variante, dazu später mehr) auch auf einem Server, oder in einem Docker-Container, gerne auch auf einem Kubernetes-Cluster in Produktion einsetzen kann, wo man sonst halt nicht so viele Werkzeuge hat, und schon gar nicht seine IDE anschließen kann um zu versuchen dort Herr der Lage zu werden.</p>
<p>Dazu möchte ich euch die Tools <a href="https://github.com/ajeetdsouza/zoxide">zoxide</a>, grep/<a href="https://github.com/BurntSushi/ripgrep">ripgrep</a>, <a href="https://github.com/junegunn/fzf">fzf</a>, less/cat/<a href="https://github.com/sharkdp/bat">bat</a> und <a href="https://direnv.net">direnv</a> vorstellen.</p>
<p>Diese Tools erleichtern viele täglich oft wiederholte Arbeitsabläufe dramatisch, und sie ermöglichen viele Use-Cases, die viele grafischen IDEs und Text-Editoren gar nicht unterstützen. Los geht es mit dem flauschigsten der Tools, fzf.</p>
<h2>Zackig die richtige Datei finden: fzf</h2>
<p><a href="https://github.com/junegunn/fzf">fzf</a> frei Eingezangendeutscht "der flauschige Kommandozeilen Finder", ist ein werkzeug um Dateien (aber auch beliebige andere Dinge) anhand von teilen des Namens oder Mustern wie jeder erste Buchstabe der Wörter ihres Namens zu finden. Dazu bietet dieses Werkzeug eine Oberfläche die interaktiv die Liste der Auswahlmöglichkeiten filtert während man tippt. Die meisten IDEs bieten so eine Funktion irgendwo mehr oder weniger gut versteckt an, und dieses Werkzeug portiert diese Funktionalität als generisches Werkzeug in die Shell.</p>
<p>Als beispiel: Ich möchte einen bestimmten UnitTest ausführen:</p>
<div class="hll"><pre><span></span>$<span class="w"> </span>bin/run_tests_in_docker.sh<span class="w"> </span><span class="k">$(</span>fzf<span class="k">)</span>
</pre></div>
<p>Mit diesem Kommando, wird zuerst fzf aufgerufen (wegen <code>$(fzf)</code>) was dann eine oberfläche präsentiert, mit der man interktiv die richtige oder die richtigen Dateien auswählen kann.</p>
<div class="hll"><pre><span></span><span class="c"># ich verwende die fish shell, daher brauch ich das $ nicht</span>
❯ bin/run_tests_in_docker.sh <span class="o">(</span>fzf<span class="o">)</span>
  src/models/dokumente/tests/document_distribution_test.py
  src/controller/process_distribution/tests/models_test.py
  src/models/dokumente/tests/dokumente_test.py
  src/integration/d3/api/test/models_test.py
▌ src/models/tests/kontaktdaten_test.py
  5/448 ────────────────────────────────
<span class="o">&gt;</span> models <span class="err">&#39;</span><span class="k">test</span>.py
</pre></div>
<p>In dem Interface kann man auch mit den Pfeiltasten navigieren, oder einen Eintrag anklicken. Der von mir eingegebene Suchstring "models 'test.py" bedeutet, dass 'models' irgendwo in dem Treffer diese Buchstaben in dieser Reihenfolge vorkommen müssen, während "'test.py" erzwingt das der exakte String 'test.py' vorkommen muss.</p>
<p><a href="https://junegunn.github.io/fzf/shell-integration/">Wenn man die fzf-Integration mit der eigenen Shell aktiviert</a>, kriegt man viele weitere Integrationen in die Shell dazu. Zwei Beispiele:</p>
<ul>
<li><p><code>⌃-T</code> sucht (mit Vorschau!) nach Dateien unterhalb des aktuellen Verzeichnisses. Das ist immer dann Praktisch wenn man für ein Kommando eine Datei aus dem aktuellen Projekt als Argument übergeben muss, und spart das tippen von <code>$(fzf)</code>. Klar, mit Auto-Vervollständigung kommt man auch ans Ziel, aber das ist <em>soo</em> viel schneller. Insbesondere wenn man nicht genau im Kopf hat wo die Datei liegt, aber noch weiß was in Ihrem Namen oder Pfad vorkommen muss. Das verwende ich die ganze Zeit.</p>
</li>
<li><p><code>⌃-R</code> sucht mit <code>fzf</code> in der Shell-Historie. Das funktioniert viel besser als die Standard-Suche, die nur nach direkt zusammenhängenden Buchstaben suchen kann. Ein Beispiel: Das Wenn ich das Kommando <code>helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml | yq</code> aus meiner historie suchen möchte, müsste ich ohne <code>fzf</code> den exakten Text schreiben der in dem Kommando vorkommt.</p>
</li>
</ul>
<div class="hll"><pre><span></span>~
Search History&gt; helmtemplateexten
  76/32637 <span class="o">(</span>0<span class="o">)</span>
  02-17 18:07:03 │ helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml
  02-17 18:06:10 │ helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml <span class="o">|</span> yq
  02-17 17:59:53 │ helm template extensions ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
  02-17 20:22:18 │ helm template  extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml
  02-17 18:15:27 │ helm template --debug extensions ./k8s/extensions/ --values ./k8s/extensions/values.dev.yaml
  02-17 17:59:42 │ helm template --dry-run --debug extensions ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
▌ 02-17 17:59:29 │ helm template --dry-run --debug  ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
  02-17 17:59:36 │ helm template --dry-run --debug foo ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml
╭──────────────────────────────────────────────────────────────────────────────────────────────╮
│ helm template --dry-run --debug ./k8s/extensions/ --values ./k8s/extensions/values-dev.yaml  │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯
</pre></div>
<p>Wenn ich oft, wenn ich ein neues Terminal öffne in die gleichen Projekte navigiere, dann geht das prima über die Shell-History:</p>
<div class="hll"><pre><span></span>❯ <span class="c"># ctrl-r für history suche</span>
Search History&gt; cdmkkapi
  352/32638 <span class="o">(</span>0<span class="o">)</span> ──────────────────────────
  08-12 11:56:19 │ <span class="k">cd</span> mkk/api
  08-24 19:05:13 │ <span class="k">cd</span> ../mkk/api
▌ 05-26 08:39:19 │ <span class="k">cd</span> Code/Projekte/mkk/api
  07-29 17:02:48 │ <span class="k">cd</span> Code/Projekte/mkk/api_infra/
  02-15 08:37:01 │ <span class="k">cd</span> Code/Projekte/mkk/api_infra/monitoring/
╭──────────────────────────╮
│ <span class="k">cd</span> Code/Projekte/mkk/api │
╰──────────────────────────╯
</pre></div>
<p>Mit <a href="https://github.com/ajeetdsouza/zoxide">Zoxide</a> geht das noch besser, aber dazu später mehr.</p>
<p>So habe ich meine fzf Integration konfiguriert:</p>
<div class="hll"><pre><span></span><span class="c"># configure key-bindings for fzf-fish</span>
<span class="c"># ctrl-f directory search</span>
<span class="c"># ctrl-r history search</span>
<span class="c"># ctlr-v variables search</span>
<span class="c"># ctrl-l git log search</span>
<span class="c"># ctrl-s git status search</span>
<span class="c"># ctrl-p processes pid search</span>
fzf_configure_bindings --git_log<span class="o">=</span><span class="se">\f</span> --directory<span class="o">=</span><span class="se">\c</span>F --git_status<span class="o">=</span><span class="se">\c</span>S --processes<span class="o">=</span><span class="se">\c</span>P
</pre></div>
<p>Das geniale an fzf ist, dass es sich so wunderbar in andere Tools integrieren lässt. Hat man es installiert wird es z.B. von <a href="https://github.com/ahmetb/kubectx">KubeCTX</a> verwendet um in <code>kubectx</code> die liste der verbundenen Kubernetes Cluster zu filtern. Oder von <code>kubens</code> um die Liste der Namespaces. Tatsächlich verwenden viele Werkzeuge intern <code>fzf</code> wenn es instaliert ist. Für mich immer wieder eine schöne Überrachung, wenn ein weiteres Werkzeug das ich gerne einsetze <code>fzf</code> verwendet.</p>

    </section>
    
      <footer>
        <a href="2025/5/die-freuden-einer-gut-eingerichteten-shell-fzf/">weiterlesen…</a>
      </footer>
    
  </article>

  
    
  <article class="blog-post">
    <header>
      <h2>
        <a href="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/">
        Die Freuden einer gut eingerichteten Shell: Autocomplete
        </a>
      </h2>
      <p class="meta">
        written by Martin Häcker on <time datetime="2025-04-14">Monday, April 14, 2025</time>
      </p>
    </header>

    <section class="blog-post-body">
      <h2>Was ist schlechte Vervollständigung?</h2>
<p>Um zu verstehen was ich mit guter Auto-Completion für Shells meine, brauchen wir erst einmal eine Baseline wie eine schlechte Completion aussieht. Das lässt sich sehr gut mit Docker demonstrieren: </p>
<div class="hll"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--hostname<span class="w"> </span>shell-completion-demo<span class="w"> </span>debian
</pre></div>
<p>Erstes Experiment: <code>ls⇥⇥</code> (kein Leerzeichen vor den Tabs!)</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-commands-unconfigured.png" alt="Automatische Vervollständigung von Kommandos - unkonfiguriert"></p>
<p>Zeigt alle Kommandos die mit <code>ls</code> anfangen
Zweites Experiment: <code>ls ⇥⇥</code>
Das zeigt bei mir:</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-files-unconfigured.png" alt="Automatische Vervollständigung von Dateien - unkonfiguriert"></p>
<p>Schon mal gut, denn hier werden die Dateien im aktuellen Ordner vervollständigt.</p>
<p>Nächste Schwierigkeitsstufe - kurze und lange Optionen: <code>ls -⇥⇥</code> (Minus vor dem Tab)
Das zeigt hier nichts, genauso für lange Optionen <code>ls --⇥⇥</code> (zwei mal Minus vor dem Tab)</p>
<p>Keine Ausgabe. <code>ls</code> ist eigentlich so ungefähr das einfachste Programm das jeder Shell beiliegt. Wenn automatische Vervollständigung also irgend etwas kann, dann sollte <code>ls</code> gut funktionieren.</p>
<h2>Was ist gute Vervollständigung?</h2>
<p>Dagegen mal ein Beispiel von meinem System:</p>
<p><code>ls⇥</code> zeigt die Kommandos die mit ls anfangen, mit einer Kurzbeschreibung was diese Kommandos tun.</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-commands-configured.png" alt="Vervollständigung von Kommandos mit der Fish-Shell"></p>
<p>Schon mit einem Tab sehe ich die Dateien, und zusätzlich sehe ich als Vorschlag den letzten Befehl den ich mit <code>ls</code> abgesetzt habe und kann diesen mit <code>⌃→</code> im ganzen, oder mit  <code>→</code> wortweise akzeptieren kann.</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-files-configured.png" alt="Automatische Vervollständigung von Dateien mit der Fish Shell"></p>
<p>Ein ls -⇥<code>ergibt sofort eine Optionsliste - kurz und lang - mit einer Kurzbeschreibung was dieses Schalter tun. Ein zweites Minus und Tab</code>ls --⇥` zeigt nur noch die langen Optionen an:</p>
<p><img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-options-configured.png" alt="Vervollständigung von Optionen mit der Fish-Shell">
<img src="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/autocomplete-long-options-configured.png" alt="Vervollständigung von langen Optionen mit der Fish-Shell"></p>
<p>Natürlich kann ich mit den Pfeiltasten oder mit Tab eine der Optionen auswählen - natürlich mit ordentlichem Highlighting.
So macht arbeiten auf der Shell Spaß!</p>
<p>Falls Ihr verwirrt seid das mein ls andere Optionen anbietet als eures, dann liegt das daran <a href="https://github.com/ogham/exa">das ich ls durch exa ersetzt habe</a>.</p>
<h2>Wie könnt Ihr das bei euch nutzen?</h2>
<p>Ich nutze die <a href="https://fishshell.com">Fish-Shell</a>, da diese von Haus aus eine sehr gute Autocompletion anbietet. Das ist aber nicht für jede, denn die Syntax der Fish Shell ist etwas anders als bei Bash/ZSH - eben nicht posix kompatibel. Ich mag das Weil es logischer und Kürzer ist, aber ich komme auch nicht durcheinander mit den verschiedenen Shell-Syntaxen da ich sie schon so lange verwende.</p>
<p>Fast alle Shell Konfigrurations-Frameworks wie <a href="https://ohmyz.sh">oh-my-zsh</a> oder <a href="https://github.com/sorin-ionescu/prezto">Prezto</a> bieten zumindest etwas an das diesem Nahe kommen. Alle automatische Konfiguration stößt aber irgendwann an Ihre Grenzen wenn es um die Kommandos geht, die wir täglich benutzen. <code>docker</code> vervollständigt dann nicht compose und oder kennt die Unterkommandos davon nicht oder nur unvollständig, kubectl und helm sind notorische Kandidaten für die man sich selber kümmern muss.</p>
<p>Jetzt könnte man natürlich versuchen automatisch aus der Hilfsausgabe dieser Kommandos etwas zu generieren (das macht z.B. die Fish shell von sich aus) oder man schreibt selber etwas (argh).</p>
<p>Oder man wendet sich vertrauensvoll an das tool <a href="https://github.com/carapace-sh/carapace">carapace</a>, mit dem man die Completion für Programme komfortabel für alle Shells nachrüsten kann. Als Beispiel um die die Autocompletions für kubectl nachzurüsten, einfach <code>source &lt;(carapace kubectl zsh)</code> oder <code>carapace kubectl fish | source</code> (je nach shell) eingeben und ausprobieren ob es gefällt, und wenn ja, diese Zeile in die User-Konfiguration deiner shell eintragen und viel glücklicher sein.</p>
<p>Obacht: Man kann mit so einem Snippet</p>
<div class="hll"><pre><span></span><span class="c1"># ~/.zshrc </span>
<span class="nb">export</span><span class="w"> </span><span class="nv">CARAPACE_BRIDGES</span><span class="o">=</span><span class="s1">&#39;zsh,fish,bash,inshellisense&#39;</span><span class="w"> </span><span class="c1"># optional</span>
zstyle<span class="w"> </span><span class="s1">&#39;:completion:*&#39;</span><span class="w"> </span>format<span class="w"> </span><span class="s1">$&#39;\e[2;37mCompleting %d\e[m&#39;</span>
<span class="nb">source</span><span class="w"> </span>&lt;<span class="o">(</span>carapace<span class="w"> </span>_carapace<span class="o">)</span>
</pre></div>
<p>in seiner Shell-Konfiguration alle completer des Carapace Projekts aktivieren. Das hat mir allerdings nicht gefallen,, da ich manche der eingebauten Completer der Fish-Shell noch etwas besser finde als das was Carapace bereit stellt. Aber um Lücken zu ergänzen? Perfekt!</p>
<p>Meine Shell-Completion Konfiguration (fish!) sieht daher so aus:</p>
<div class="hll"><pre><span></span><span class="c"># enable shell completions</span>
<span class="k">set</span> --global --export CARAPACE_BRIDGES <span class="s1">&#39;zsh,fish,bash,inshellisense&#39;</span>
<span class="c"># I didn&#39;t have much luck enabling all carapace completions, but I do like some of them - especially if there is no built in fish completion for them</span>
<span class="c"># carapace _carapace | source</span>
carapace fd <span class="o">|</span> <span class="nb">source</span>
carapace bat <span class="o">|</span> <span class="nb">source</span>
carapace brew <span class="o">|</span> <span class="nb">source</span>
carapace rg <span class="o">|</span> <span class="nb">source</span>
carapace docker <span class="o">|</span> <span class="nb">source</span>
uv generate-shell-completion <span class="nb">fish</span> <span class="o">|</span> <span class="nb">source</span>
yq completion <span class="nb">fish</span> <span class="o">|</span> <span class="nb">source</span>
</pre></div>

    </section>
    
      <footer>
        <a href="2025/4/die-freuden-einer-gut-eingerichteten-shell-autocomplete/">weiterlesen…</a>
      </footer>
    
  </article>

  
  
  
    
  <div class="pagination">
    
      <span class="disabled">&laquo; Previous</span>
    
    | 1 |
    
      <a href="page/2/">Next &raquo;</a>
    
  </div>

  

    </article>
    <footer class="container-fluid ">
      <ul class="nav">
  <li class="nav-item copyright">
    <span class="nav-link">&copy; 2025 <a href="../work/">Martin Häcker</a></span>
  </li>
  
    
    <li class="nav-item imprint">
      <a class="nav-link" href="../meta/#imprint">
        Imprint
      </a></li>
  
    
    <li class="nav-item privacy-policy">
      <a class="nav-link" href="../meta/#privacy-policy">
        Privacy Policy
      </a></li>
  
    
    <li class="nav-item colophon">
      <a class="nav-link" href="../meta/#colophon">
        Colophon
      </a></li>
  
  <li class="ml-auto nav-item rss-feed">
    <a class="nav-link" href="../../blog/feed.xml">
      <img class="rss-icon" src=/static/rss.svg height=25 width=25>
      <span class="sr-only">RSS-Feed</span>
    </a>
  </li>
  <li class="nav-item license">
    <a class="nav-link" 
      rel="license" 
      target="_blank" 
      href="https://creativecommons.org/licenses/by-sa/4.0/deed"
    >
      <img 
        src="/static/cc-by-sa-88x31.png"
        alt="Creative Commons Attribution - Share Alike 4.0 International Lizense"
      >
    </a>
  </li>
</ul>
    </footer>
  </body>
</html>
